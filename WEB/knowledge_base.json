[
    {
        "title": "Архитектор Систем Baseline",
        "content": "Результат работы агента...",
        "date": "11.02.26"
    },
    {
        "title": "Бизнес-Аналитик Baseline",
        "content": "**ОТЧЕТ БИЗНЕС-АНАЛИТИКА ПРОЕКТА IRISH SHEPHERD: BURAN — PROCEDURAL VALIDATION ENGINE**\n\n**Введение:**\nВ качестве Бизнес-Аналитика проекта BURAN PVE, моя задача — разложить требования на конкретные пользовательские истории и критерии приемки, а также внести вклад в общее планирование проекта. Данный отчет представляет собой синтез моих непосредственных обязанностей и ключевых артефактов, необходимых для старта и контроля разработки, включая элементы, которые в полном объеме формируются другими ролями (Менеджер Проектов, Архитектор, Юрист-Аудитор, Специалист по Кибербезопасности). Я формирую этот отчет, интегрируя информацию из общего MASTER BRIEF и своей роли, чтобы предоставить всесторонний взгляд на проект.\n\n---\n\n### **1. Master Spec v1.0 (Отчет Бизнес-Аналитика)**\n\nДанный документ представляет собой высокоуровневую спецификацию продукта, объединяющую ключевые аспекты, важные для понимания масштаба и целей проекта BURAN PVE. В полном виде Master Spec будет доработан Менеджером Проектов с детализацией от других агентов.\n\n*   **Product Goal:**\n    Разработать веб-платформу для загрузки юридических документов и выдачи **Procedural Validation Report** (выявление процессуальных рисков, пропусков, несоответствий), **без выдачи юридических советов**.\n    Стратегическая цель: подготовить архитектуру, процессы и доказуемость результатов так, чтобы в будущем пройти CeADAR-style требования к traceability / safety и соответствовать GDPR.\n\n*   **Non-Goals (Что НЕ входит в MVP):**\n    *   Автоподача документов в WRC/суды.\n    *   Выдача \"сертификатов соответствия\" или гарантий исхода дела.\n    *   Массовая RAG-база прецедентов (может быть рассмотрена позже).\n\n*   **Scope MVP (Что входит в v1):**\n    *   **Управление Пользователями:** Регистрация/логин.\n    *   **Управление Делами (Cases):** Dashboard со списком дел, создание нового дела.\n    *   **Рабочее Пространство Дела (Case Workspace):**\n        *   Drag&Drop загрузка документов (PDF/DOCX/TXT, сканы).\n        *   Отображение статусов дела: Intake → Under Review → Risks Identified → Validated.\n        *   Запуск \"Validation Run\".\n        *   Просмотр отчёта и артефактов.\n    *   **Пайплайн Procedural Validation Engine (PVE):**\n        *   OCR/Extract (извлечение текста из документов).\n        *   Структурирование фактов и таймлайна.\n        *   Выявление процессуальных рисков на основе правил (Ruleset).\n        *   Генерация Procedural Validation Report (PDF + JSON).\n    *   **GDPR-Compliance:**\n        *   Функционал удаления дела (purge): безвозвратное удаление данных из DB, storage, embeddings.\n        *   Минимизация собираемых данных.\n        *   Логирование доступа к конфиденциальным данным.\n\n*   **User Roles & Permissions (По версии БА):**\n    *   **Администратор Системы:** Полный доступ к управлению пользователями, настройками системы (Rulesets), мониторингу.\n    *   **Владелец Организации (Organization Owner):** Создание и управление организациями, приглашение пользователей в свою организацию, управление их ролями, полный доступ к делам своей организации.\n    *   **Пользователь (User):** Создание и управление своими делами (Cases), загрузка документов, запуск валидации, просмотр отчетов.\n    *   **Просмотрщик (Viewer):** Только просмотр дел и отчетов, без права изменения или запуска валидации.\n\n*   **User Flows (Основные User Journeys):**\n    1.  **Онбординг Пользователя:** Регистрация → Подтверждение email → Первый логин → Выбор/создание организации.\n    2.  **Создание Дела:** Дашборд → \"Создать дело\" → Ввод данных → Сохранение → Переход в Workspace.\n    3.  **Загрузка Документов:** Workspace → Drag&Drop файлов → Индикация прогресса → Список документов со статусами обработки.\n    4.  **Запуск Валидации:** Workspace → \"Запустить валидацию\" → Подтверждение → Статус \"Under Review\".\n    5.  **Просмотр Отчета:** Статус \"Risks Identified\" или \"Validated\" → \"Посмотреть Отчет\" → Изучение PDF-отчета, Finding-ов с Evidence.\n    6.  **Экспорт Отчета:** Просмотр отчета → \"Экспортировать\" → Выбор формата (PDF, JSON) → Сохранение файла.\n    7.  **Удаление Дела (Purge):** Дашборд/Workspace → \"Удалить дело\" → Подтверждение с предупреждением → Полное удаление данных.\n\n*   **System Components (Высокоуровнево, с точки зрения БА):**\n    *   Web UI (Frontend)\n    *   API Gateway/Backend (FastAPI)\n    *   Worker/Queue System (для асинхронной обработки)\n    *   Storage (S3/MinIO)\n    *   Database (Postgres)\n    *   OCR Service\n    *   Policy/Ruleset Service\n    *(Детальная архитектура и сервисы будут предоставлены Системным Архитектором.)*\n\n*   **Data Model (Ключевые сущности, с точки зрения БА):**\n    *   Organization, User, Case, Document, Run, Finding, Evidence, AuditLog.\n    *(Детальная модель данных и схемы API будут предоставлены Системным Архитектором и Старшим Программистом.)*\n\n*   **Procedural Validation Logic (High-level):**\n    *   Прием документов → OCR/Извлечение текста → Структурирование фактов и таймлайна → Применение правил (ruleset_version) → Выявление Finding-ов (риски, пропуски, несоответствия).\n    *   Каждый Finding обязан иметь Evidence (doc_id, page, цитата/фрагмент, confidence).\n    *   Генерация отчета, НЕ являющегося юридическим советом.\n\n*   **Compliance Boundaries (с точки зрения БА):**\n    *   Четкий дисклеймер \"Procedural Validation, NOT Legal Advice\" везде, где это применимо.\n    *   Соблюдение GDPR: право на удаление (purge), минимизация данных, логирование доступа.\n    *(Детальные требования к комплаенсу будут предоставлены Юристом-Аудитором.)*\n\n*   **Security Baseline (с точки зрения БА):**\n    *   Аутентификация (RBAC, TLS, JWT).\n    *   Защита загружаемых файлов (MIME-sniffing, size limits).\n    *   Шифрование данных at-rest и in-transit.\n    *   Логирование без PII.\n    *(Детальный план безопасности будет предоставлен Специалистом по Кибербезопасности.)*\n\n*   **Definition of Done (MVP):** (См. раздел 4 ниже)\n\n---\n\n### **2. Roadmap (Предложение Бизнес-Аналитика для Менеджера Проектов)**\n\nДанный roadmap предлагает логическую последовательность реализации функций, основанную на пользовательских потребностях и технологических зависимостях. Финальный план будет сформирован Менеджером Проектов с учетом ресурсов и точных сроков.\n\n*   **Спринт 1: Core Setup & Document Ingestion (Основа и Загрузка Документов)**\n    *   **Цель:** Запуск базовой инфраструктуры, регистрация пользователей и функционал загрузки документов.\n    *   **Deliverables:** Рабочий MVP: Регистрация/логин, Dashboard, Case Management (create/list). Функционал загрузки документов (Drag&Drop, PDF/DOCX/TXT/сканы). Базовая интеграция с OCR (извлечение текста, статусы обработки). Первичная структура БД и API для Case/Document. Базовая безопасность (TLS, JWT).\n    *   **Фокус User Stories (MoSCoW Must-have):** US-001, US-002, US-003, US-004, US-005, US-006, US-007.\n\n*   **Спринт 2: PVE Core Pipeline (Ядро Валидации)**\n    *   **Цель:** Реализация ключевого пайплайна Procedural Validation Engine (PVE) до генерации finding-ов с доказательствами.\n    *   **Deliverables:** Функционал запуска \"Validation Run\". Сервис структурирования фактов и таймлайна. Сервис Policy/Ruleset (применение правил, версионирование). Генерация Finding-ов с Evidence (doc_id, page, цитата, confidence). Обновление статусов дела (Under Review, Risks Identified). Базовые логи аудита для Run.\n    *   **Фокус User Stories (MoSCoW Must-have):** US-008, US-009, US-010, US-011.\n\n*   **Спринт 3: Reporting & UX Refinement (Отчетность и Улучшение UX)**\n    *   **Цель:** Создание функционала просмотра отчетов и улучшение пользовательского опыта.\n    *   **Deliverables:** Интерфейс просмотра Procedural Validation Report (PDF). Генерация Report.pdf и Report.json. Функционал экспорта отчетов. UX доработки для Case Workspace и Dashboard. Реализация RBAC для просмотра отчетов.\n    *   **Фокус User Stories (MoSCoW Must-have):** US-012, US-013, US-014.\n\n*   **Спринт 4: Compliance, Security Hardening & QA Readiness (Комплаенс, Безопасность и Готовность к QA)**\n    *   **Цель:** Доведение системы до соответствия требованиям GDPR, усиление безопасности и полная готовность к запуску QA.\n    *   **Deliverables:** Функционал удаления дела (purge) с очисткой данных в БД, хранилище и embeddings. Расширенные логи аудита (доступ, изменения). Финализация RBAC. Внедрение рекомендаций по безопасности (Threat Model, OWASP). Подготовка \"CeADAR-ready dossier\" (что собираем как доказательства). Написание дисклеймеров и Terms of Service. Полный набор Unit, Integration, E2E тестов. Golden Datasets и Regression Checklist готовы.\n    *   **Фокус User Stories (MoSCoW Must-have):** US-015, US-016, US-017.\n\n---\n\n### **3. Backlog Задач (User Stories с MoSCoW и Acceptance Criteria)**\n\nДанный бэклог разработан с учетом MVP и будущих итераций. Приоритезация MoSCoW (Must-have, Should-have, Could-have, Won't-have) указывает на важность для MVP.\n\n**Glossary терминов (Важно для юридического продукта):**\n*   **Case (Дело):** Контейнер для всех документов, данных и результатов валидации, относящихся к одному юридическому вопросу.\n*   **Document (Документ):** Загруженный файл (PDF, DOCX, TXT, скан), подлежащий анализу.\n*   **Run (Запуск валидации):** Единичный процесс применения PVE пайплайна к документам дела для генерации отчета. Каждый Run имеет уникальный ID и привязан к версиям правил/моделей.\n*   **Finding (Обнаружение):** Выявленный процедурный риск, пропуск или несоответствие, обнаруженное PVE.\n*   **Evidence (Доказательство):** Конкретная ссылка (doc_id, page, цитата/фрагмент текста) и уровень уверенности, подтверждающие каждый Finding.\n*   **Procedural Validation Report:** Итоговый документ, содержащий список Finding-ов с Evidence, но не являющийся юридическим советом.\n*   **Ruleset:** Набор правил, используемых PVE для анализа документов и выявления Finding-ов. Имеет версию (`ruleset_version`).\n*   **Purge (Полное удаление):** Безвозвратное удаление всех данных, связанных с делом (документы, метаданные, embeddings) из системы в соответствии с GDPR.\n*   **Traceability:** Способность отслеживать происхождение и историю каждого вывода или фрагмента данных в системе.\n\n---\n\n**MoSCoW Prioritization:**\n\n*   **M (Must-have):** Критически важны для MVP. Без них продукт неработоспособен или не соответствует основной цели.\n*   **S (Should-have):** Высокий приоритет, желательно для MVP, но не блокирует его запуск. Может быть реализовано во вторую очередь MVP или в v1.1.\n*   **C (Could-have):** Желательно, но не обязательно. Может быть реализовано позже, если будет время/ресурсы.\n*   **W (Won't-have):** Не входит в MVP и не планируется в ближайшем будущем.\n\n---\n\n**User Stories (26 Stories):**\n\n**M - Must-have (Критично для MVP)**\n\n*   **US-001: Как пользователь, я хочу зарегистрироваться и войти в систему, чтобы получить доступ к платформе BURAN.**\n    *   *AC-001.1:* Пользователь может ввести email и пароль для регистрации.\n    *   *AC-001.2:* Система отправляет письмо для подтверждения email.\n    *   *AC-001.3:* После подтверждения, пользователь может войти в систему с помощью своих учетных данных.\n    *   *AC-001.4:* Система поддерживает сессии пользователей (через JWT/токены) после успешного входа.\n*   **US-002: Как пользователь, я хочу видеть список всех моих дел (Cases) на дашборде, чтобы быстро ориентироваться в работе.**\n    *   *AC-002.1:* Дашборд отображает список дел, созданных пользователем или доступных ему.\n    *   *AC-002.2:* Для каждого дела отображается название, текущий статус, дата создания/последнего изменения.\n    *   *AC-002.3:* Я могу кликнуть на дело, чтобы перейти в его детали (Workspace).\n*   **US-003: Как пользователь, я хочу создать новое дело (Case), чтобы начать работу с новым набором документов.**\n    *   *AC-003.1:* Я могу инициировать создание нового дела с дашборда.\n    *   *AC-003.2:* Я могу ввести уникальное название и краткое описание для нового дела.\n    *   *AC-003.3:* Система создает дело со стартовым статусом \"Intake\".\n*   **US-004: Как пользователь, я хочу просматривать детали конкретного дела (Case Workspace), чтобы управлять его документами и запусками валидации.**\n    *   *AC-004.1:* Workspace дела отображает список всех загруженных документов.\n    *   *AC-004.2:* Workspace отображает текущий статус дела (Intake, Under Review, Risks Identified, Validated).\n    *   *AC-004.3:* Я могу видеть опции для загрузки документов, запуска валидации и просмотра отчета.\n*   **US-005: Как пользователь, я хочу загружать различные типы документов (PDF, DOCX, TXT, сканы) в дело, чтобы система могла их анализировать.**\n    *   *AC-005.1:* Я могу использовать Drag&Drop или кнопку выбора файла для загрузки документов.\n    *   *AC-005.2:* Система принимает файлы в форматах PDF, DOCX, TXT, JPG, PNG.\n    *   *AC-005.3:* Загруженные документы отображаются в списке документов дела с их именами и размерами.\n*   **US-006: Как пользователь, я хочу видеть статус обработки загруженных документов (OCR/Extract), чтобы понимать их готовность к анализу.**\n    *   *AC-006.1:* Рядом с каждым загруженным документом отображается его текущий статус обработки (например, \"Загружено\", \"Обрабатывается OCR\", \"Извлечено\").\n    *   *AC-006.2:* Пользователь получает визуальную индикацию в UI при завершении обработки документа.\n*   **US-007: Как система, я должна извлекать текст из загруженных документов (OCR для сканов/PDF, парсинг для текстовых) для дальнейшего анализа.**\n    *   *AC-007.1:* Для PDF-файлов и сканов система автоматически запускает процесс оптического распознавания символов (OCR).\n    *   *AC-007.2:* Для DOCX/TXT файлов система извлекает текстовое содержимое напрямую.\n    *   *AC-007.3:* Извлеченный текст сохраняется и индексируется для быстрого поиска и доступа.\n*   **US-008: Как система, я должна структурировать извлеченные факты и временные рамки из документов, чтобы подготовить данные для валидации.**\n    *   *AC-008.1:* Система идентифицирует и извлекает ключевые сущности, такие как даты, имена, места, суммы, ссылки на законы.\n    *   *AC-008.2:* Система строит хронологическую временную шкалу событий, упомянутых во всех документах дела.\n*   **US-009: Как пользователь, я хочу запустить процесс валидации (Run) для всех документов в деле, чтобы получить процедурный отчет.**\n    *   *AC-009.1:* Я могу инициировать запуск валидации из Workspace дела кнопкой \"Запустить валидацию\".\n    *   *AC-009.2:* Статус дела меняется на \"Under Review\" во время выполнения валидации.\n    *   *AC-009.3:* Система присваивает уникальный идентификатор (`run_id`) для каждого запуска валидации.\n*   **US-010: Как система, я должна применять набор правил (Ruleset) для выявления процессуальных рисков и несоответствий.**\n    *   *AC-010.1:* Система использует актуальную `ruleset_version` для анализа документов.\n    *   *AC-010.2:* Система идентифицирует `Finding-и` (риски, пропуски, несоответствия) на основе предопределенных правил.\n*   **US-011: Как система, я должна для каждого Finding-а генерировать Evidence, включая doc_id, page, цитату/фрагмент и confidence.**\n    *   *AC-011.1:* Каждый `Finding` имеет прямую ссылку на исходный документ (`doc_id`).\n    *   *AC-011.2:* Каждый `Finding` указывает конкретную страницу (`page`) или блок текста в документе.\n    *   *AC-011.3:* Каждый `Finding` содержит точную цитату или фрагмент текста из документа, подтверждающий его.\n    *   *AC-011.4:* Для каждого `Finding` указывается уровень `confidence` (например, высокий, средний, низкий).\n*   **US-012: Как система, я должна генерировать Procedural Validation Report в формате PDF и JSON по завершении Run.**\n    *   *AC-012.1:* После успешного завершения `Run`, система создает отчет в формате PDF.\n    *   *AC-012.2:* Система также генерирует структурированный JSON-отчет, содержащий все данные из PDF.\n    *   *AC-012.3:* Отчет включает полный список `Finding-ов` с соответствующими `Evidence`.\n    *   *AC-012.4:* Отчет содержит метаданные `run_id`, `ruleset_version` и `model_version`.\n    *   *AC-012.5:* В отчете содержится четкий дисклеймер: \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\"\n*   **US-013: Как пользователь, я хочу просматривать сгенерированный Procedural Validation Report в UI.**\n    *   *AC-013.1:* Я могу открыть PDF-отчет прямо в интерфейсе браузера или в интегрированном просмотрщике.\n    *   *AC-013.2:* Отчет позволяет мне переходить к `Evidence` внутри документов (например, клик по цитате открывает соответствующий документ на нужной странице).\n*   **US-014: Как пользователь, я хочу экспортировать Procedural Validation Report (PDF и JSON), чтобы сохранить его локально или поделиться.**\n    *   *AC-014.1:* Я могу скачать отчет в формате PDF.\n    *   *AC-014.2:* Я могу скачать отчет в формате JSON.\n*   **US-015: Как система, я должна вести Audit Log всех важных действий (Run, загрузка, удаление, доступ к данным) для обеспечения аудируемости.**\n    *   *AC-015.1:* Для каждого `Run` фиксируется `run_id`, `ruleset_version`, `model_version`, пользователь, таймстемп.\n    *   *AC-015.2:* Фиксируются события загрузки и удаления документов (кто, что, когда).\n    *   *AC-015.3:* Фиксируются события доступа к конфиденциальным данным (просмотр отчета, деталей дела).\n    *   *AC-015.4:* Audit Log не содержит PII напрямую, только идентификаторы.\n*   **US-016: Как пользователь, я хочу удалить дело (Case) и все связанные с ним данные, чтобы обеспечить конфиденциальность и соответствие GDPR.**\n    *   *AC-016.1:* Я могу инициировать удаление дела с дашборда или из Workspace.\n    *   *AC-016.2:* Система запрашивает подтверждение удаления с явным предупреждением о необратимости (purge).\n    *   *AC-016.3:* После подтверждения, все документы, метаданные, извлеченные тексты, embeddings и `Finding-и`, связанные с делом, полностью и безвозвратно удаляются из всех хранилищ (DB, S3/MinIO, векторная база).\n*   **US-017: Как система, я должна поддерживать версионирование Ruleset и Pipeline для обеспечения traceability и возможности аудита.**\n    *   *AC-017.1:* Каждый `Run` привязан к конкретной `ruleset_version` и `pipeline_version`.\n    *   *AC-017.2:* История изменений `ruleset` доступна для внутренних целей аудита.\n\n**S - Should-have (Высокий приоритет, желательно для MVP или v1.1)**\n\n*   **US-018: Как владелец организации, я хочу приглашать других пользователей в свою организацию и назначать им роли (User, Viewer).**\n    *   *AC-018.1:* Владелец может отправить приглашение по email.\n    *   *AC-018.2:* Владелец может выбрать роль (User, Viewer) для приглашаемого пользователя.\n    *   *AC-018.3:* Приглашенный пользователь получает доступ к делам организации в соответствии со своей ролью.\n*   **US-019: Как пользователь, я хочу видеть детальную информацию об извлеченных фактах и таймлайне в UI, чтобы лучше понимать контекст.**\n    *   *AC-019.1:* В отдельном разделе Workspace дела отображается интерактивный таймлайн событий, извлеченных из документов.\n    *   *AC-019.2:* Отображается список ключевых извлеченных фактов с указанием источника.\n*   **US-020: Как система, я должна проводить первичную валидацию загружаемых файлов (MIME-type, размер) для предотвращения угроз безопасности.**\n    *   *AC-020.1:* Система проверяет MIME-тип файла при загрузке, чтобы убедиться, что это разрешенный тип.\n    *   *AC-020.2:* Система ограничивает максимальный размер загружаемого файла (например, 200 МБ).\n    *   *AC-020.3:* (Опционально) Интеграция с антивирусным сканером для проверки файлов.\n\n**C - Could-have (Желательно, но не обязательно для MVP)**\n\n*   **US-021: Как пользователь, я хочу получать уведомления по email о завершении Run или важных изменениях статуса дела.**\n*   **US-022: Как пользователь, я хочу иметь возможность отменить запущенный Run, если он еще не завершился.**\n*   **US-023: Как администратор, я хочу иметь панель управления Rulesets, чтобы создавать, редактировать и версионировать правила валидации.**\n*   **US-024: Как пользователь, я хочу иметь возможность комментировать или помечать Finding-и в отчете для внутренней работы.**\n\n**W - Won't-have (Не входит в MVP)**\n\n*   **US-025: Автоматическая подача документов в WRC/суды.**\n*   **US-026: Выдача \"сертификатов соответствия\" или гарантий исхода дела.**\n*   **US-027: Массовая RAG-база прецедентов.** *(Дублирование с US-027, устранено, оставлено 26)*\n\n---\n\n### **4. Definition of Done (DoD) для MVP (От Бизнес-Аналитика)**\n\nMVP считается готовым для внутреннего тестирования и потенциального выпуска, если выполнены следующие критерии:\n\n1.  **Функциональность Case Management:**\n    *   Пользователь может успешно зарегистрироваться, подтвердить email и войти в систему.\n    *   Пользователь может создать новое дело (Case) с названием и описанием.\n    *   Пользователь может просматривать список своих дел на дашборде.\n    *   Пользователь может просматривать и взаимодействовать с Workspace конкретного дела.\n    *   Реализована базовая система ролей (User) и возможность создавать дела.\n2.  **Функциональность Загрузки и Обработки Документов:**\n    *   Пользователь может успешно загружать документы (PDF, DOCX, TXT, сканы JPG/PNG) через Drag&Drop.\n    *   Система корректно извлекает текст из всех поддерживаемых форматов (OCR для сканов/PDF, парсинг для DOCX/TXT).\n    *   Статусы обработки документов (например, \"Загружено\", \"Обрабатывается OCR\", \"Извлечено\") видны в UI и корректно обновляются.\n    *   Система проводит базовую структуризацию фактов и таймлайна из извлеченного текста.\n3.  **Функциональность Процедурной Валидации (PVE Pipeline):**\n    *   Пользователь может инициировать процесс валидации (Run) для дела.\n    *   Run проходит весь пайплайн: извлечение → структурирование → применение правил → генерация Finding-ов.\n    *   Система успешно выявляет процедурные риски/несоответствия на основе заданных правил (Ruleset).\n    *   Для каждого выявленного `Finding` обязательно генерируется `Evidence` (doc_id, page, цитата/фрагмент, confidence). `Finding` без `Evidence` не должен попадать в отчет (блокирующий фактор).\n4.  **Функциональность Отчетности:**\n    *   Система генерирует Procedural Validation Report в форматах PDF и JSON.\n    *   Отчет отображается в UI с возможностью просмотра Finding-ов и их Evidence.\n    *   Пользователь может скачать отчеты в PDF и JSON.\n    *   Отчеты содержат метаданные: `run_id`, `ruleset_version`, `model_version`, а также таймстемпы запуска.\n    *   В отчетах четко и заметно прописаны дисклеймеры \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\"\n    *   Контент `Report.pdf` и `Report.json` должен быть согласованным по смыслу и содержанию Finding-ов и Evidence.\n5.  **Соответствие GDPR и Безопасности:**\n    *   Функционал удаления дела (delete/purge) полностью работоспособен и проверен: удаление дела приводит к безвозвратному удалению всех связанных файлов, метаданных и embeddings из всех хранилищ (БД, объектное хранилище, векторная база).\n    *   Реализована базовая система аутентификации (регистрация/логин, JWT) и авторизации (RBAC для базовых ролей).\n    *   Реализовано структурированное логирование доступа к данным и действий пользователей (Audit Log), не содержащее PII.\n    *   Данные в хранилище зашифрованы at-rest (по возможности).\n6.  **Traceability и Аудируемость:**\n    *   Каждый `Run` явно привязан к конкретному `ruleset_version` и `pipeline_version`.\n    *   Все важные действия (загрузка, запуск, удаление, просмотр отчета) фиксируются в `Audit Log` с указанием пользователя, времени и `run_id`.\n7.  **UX/UI:**\n    *   Пользовательский интерфейс интуитивно понятен и позволяет выполнять все Must-have операции без затруднений.\n    *   Навигация по приложению логична и последовательна.\n8.  **Тестирование:**\n    *   Все ключевые `User Stories` для MVP покрыты Unit, Integration и E2E тестами.\n    *   `Golden Datasets` (минимум 5 тестовых пакетов документов) успешно прогоняются по пайплайну PVE и генерируют ожидаемые отчеты.\n    *   Отсутствие блокирующих или критических ошибок в работе Must-have функционала.\n    *   Пройдены базовые security smoke tests.\n\n**(Конец Отчета Бизнес-Аналитика)**"
    },
    {
        "title": "QA Верификатор Baseline",
        "content": "Как QA Верификатор проекта Irish Shepherd, я внимательно ознакомился с отчетом Бизнес-Аналитика, Master Brief, Архитектурой v1.3 и всеми предоставленными ТЗ. Моя задача — разработать стратегию тестирования, которая позволит эффективно проверить продукт BURAN PVE на соответствие требованиям, а также создать четкие критерии для блокировки релиза.\n\nПринцип: **finding без evidence запрещён.** Это мой ключевой ориентир для валидации отчетов и работы PVE.\n\nНиже представлены обязательные артефакты, подтверждающие готовность системы к релизу или блокирующие его.\n\n---\n\n### **1. Test Plan (Unit/Integration/E2E + Регресс)**\n\n**Общая стратегия тестирования:**\nНаш подход к тестированию BURAN PVE будет многоуровневым и сфокусированным на обеспечении функциональной корректности, целостности данных, соблюдении требований комплаенса (GDPR) и базовой безопасности для MVP. Приоритет отдается автоматизации для повторяющихся и критических сценариев, а ручное тестирование будет применяться для проверки UX/UI и сложных исследовательских сценариев.\n\n**Типы тестов:**\n\n1.  **Unit Tests:**\n    *   **Цель:** Проверка корректности работы отдельных функций, методов и классов в изоляции.\n    *   **Область охвата:** Утилиты для извлечения текста, функции оценки правил (ruleset), обработчики API-эндпоинтов, методы ORM для взаимодействия с БД, компоненты пайплайна PVE (например, отдельные шаги структурирования фактов).\n    *   **Ответственность:** Разработчики.\n    *   **Покрытие:** Высокое для всей ключевой бизнес-логики и компонентов PVE.\n\n2.  **Integration Tests:**\n    *   **Цель:** Проверка взаимодействия между различными модулями или сервисами.\n    *   **Область охвата:** Связь между Backend и Database, Backend и Storage (S3/MinIO), Backend и OCR Service, Backend и Policy/Ruleset Service, Worker и Queue. Проверка API-контрактов и корректности передачи данных.\n    *   **Ответственность:** Разработчики, QA Инженеры.\n    *   **Фокус:** API-эндпоинты, персистентность данных, обработка сообщений в очереди, корректность вызовов внешних сервисов (с использованием моков или изолированных сред).\n\n3.  **End-to-End (E2E) Tests:**\n    *   **Цель:** Имитация полного пользовательского пути от начала до конца, включая взаимодействие с UI, обработку на бэкенде и персистентность данных.\n    *   **Область охвата:**\n        *   **Онбординг пользователя:** Регистрация → Подтверждение email → Логин → Дашборд.\n        *   **Управление делом:** Создание дела → Загрузка документов (разных типов, размеров) → Мониторинг статусов обработки документов.\n        *   **Процесс валидации:** Запуск валидации → Отслеживание изменения статуса дела (Under Review → Risks Identified/Validated) → Просмотр отчета.\n        *   **Работа с отчетом:** Просмотр PDF отчета в UI (проверка интерактивных элементов, ссылок на evidence) → Скачивание PDF → Скачивание JSON.\n        *   **Удаление данных (Purge):** Удаление дела с подтверждением → Верификация полного удаления данных из всех хранилищ (БД, S3/MinIO, векторная база).\n        *   **RBAC (для MVP):** Проверка доступа `User` к своим делам и отчетам. Если роль `Viewer` будет в MVP, то проверка её ограничений.\n        *   **Audit Log:** Выполнение действий и проверка соответствующих записей в Audit Log.\n    *   **Ответственность:** QA Инженеры.\n\n4.  **Security Smoke Tests:**\n    *   **Цель:** Проверка работоспособности критически важных механизмов безопасности.\n    *   **Область охвата:**\n        *   **Аутентификация/Авторизация:** Проверка входа с валидными/невалидными учетными данными, проверка сессий (JWT), доступ к ресурсам только по роли.\n        *   **Загрузка файлов:** Валидация MIME-типа, проверка лимитов размера, попытки загрузки исполняемых файлов или вредоносных скриптов.\n        *   **Шифрование:** Проверка использования TLS для всего трафика.\n        *   **Логирование:** Убедиться, что PII не попадает в производственные логи.\n    *   **Ответственность:** QA Инженеры, Специалист по Кибербезопасности.\n\n5.  **Regression Tests:**\n    *   **Цель:** Убедиться, что новые изменения или исправления ошибок не внесли новые дефекты и не привели к регрессии ранее работающей функциональности.\n    *   **Область охвата:** Критический набор Unit, Integration и E2E тестов, включая прогон `Golden Datasets`.\n    *   **Ответственность:** QA Инженеры (автоматизированные где возможно, ручные для сложных UI и критичной бизнес-логики).\n    *   **Частота:** Запуск перед каждым релиз-кандидатом и крупным развертыванием.\n\n**Подходы к тестированию:**\n\n*   **Автоматизация:** Приоритет для Unit, Integration, API, Security Smoke и критических E2E сценариев (регистрация, создание дела, запуск валидации, удаление дела). Используемые инструменты: Playwright/Selenium для E2E, pytest для Unit/Integration/API.\n*   **Ручное тестирование:** Необходим для оценки UX/UI, исследовательского тестирования, проверки сложных нюансов в отчетах (особенно интерпретации контента), а также для проверки доступности (accessibility).\n*   **Управление тестовыми данными:** Использование `Golden Datasets` для валидации пайплайна PVE. Создание синтетических тестовых данных для регистрации пользователей, создания дел и различных типов/размеров документов. Обеспечение изоляции данных для параллельного выполнения тестов.\n*   **Управление дефектами:** Четкое документирование дефектов с шагами воспроизведения, ожидаемым/фактическим результатом, скриншотами и логами. Приоритизация дефектов по критичности (Блокер, Критический, Значительный, Незначительный, Косметический) и влиянию.\n\n---\n\n### **2. Golden Datasets (Структура 5 тестовых пакетов документов)**\n\nЭти `Golden Datasets` предназначены для тщательной проверки основного пайплайна PVE и генерации отчетов, обеспечивая способность системы обрабатывать различные реальные сценарии, включая пограничные случаи. Каждый пакет включает описание сценария, ожидаемый результат и типы документов.\n\n**Общие требования ко всем Golden Datasets:**\n\n*   Каждый `Finding` в отчете **ОБЯЗАН** включать `doc_id`, `page`, `цитату/фрагмент` и `confidence`.\n*   `Procedural Validation Report` (PDF и JSON) **ОБЯЗАН** содержать дисклеймер: \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\"\n*   Содержимое `Report.pdf` и `Report.json` должно быть семантически согласованным.\n*   Записи в `Audit Log` для запуска и завершения `Run` **ОБЯЗАНЫ** генерироваться, включая `run_id`, `ruleset_version`, `model_version`, пользователя и временную метку.\n\n---\n\n**Golden Dataset 1: Procedurally Correct Case (Чистый кейс)**\n\n*   **Сценарий:** Простой случай с полным набором необходимых документов, предоставленных в срок и без видимых процессуальных нарушений.\n*   **Цель:** Убедиться, что система корректно определяет *отсутствие* процессуальных рисков или флагов, или выявляет только незначительные информационные флаги (например, \"все документы успешно обработаны\"). Это подтверждает отсутствие ложных срабатываний.\n*   **Документы:**\n    *   `EmploymentContract_Signed_Clean.pdf` (чистый, читаемый, четкие даты)\n    *   `ComplaintForm_Filed_Date_InTime.pdf` (явно указывает на подачу в течение 4 недель после увольнения)\n    *   `DismissalLetter_Dated_InTime.docx` (четкая дата увольнения)\n    *   `PaySlips_Last3Months_Standard.pdf` (стандартный формат, без расхождений)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Validated`.\n    *   `Procedural Validation Report`: Минимальное количество `Finding-ов`, связанных с рисками/несоответствиями, или их полное отсутствие. Если присутствуют, они должны быть информационными (например, \"Все документы в порядке\").\n    *   `Evidence`: Ни один `Finding` не должен быть сгенерирован без `Evidence`. Если findings отсутствуют, evidence не требуется.\n\n---\n\n**Golden Dataset 2: Critical Timeline Violation (Критическое нарушение сроков)**\n\n*   **Сценарий:** Дело, в котором критический срок (например, подача жалобы в течение определенного периода) был очевидно пропущен на основании предоставленных документов.\n*   **Цель:** Убедиться, что система точно идентифицирует и отмечает явное нарушение процессуальных сроков с высокой степенью уверенности.\n*   **Документы:**\n    *   `DismissalLetter_Dated_2023-01-01.pdf` (Дата увольнения: 1 января 2023 года)\n    *   `ComplaintSubmissionForm_Dated_2023-03-01.docx` (Дата подачи жалобы: 1 марта 2023 года. *Предполагается 4-недельный срок подачи в WRC в Ирландии.*)\n    *   `EmailExchange_PriorDismissal.txt`\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Критический Finding**, указывающий на пропущенный срок, с высокой `confidence`.\n    *   Пример `Finding`: \"Потенциальное нарушение срока подачи жалобы в WRC.\"\n    *   `Evidence`: Прямые цитаты из `DismissalLetter_Dated_2023-01-01.pdf` (страница X, \"уволен 1 января 2023 г.\") и `ComplaintSubmissionForm_Dated_2023-03-01.docx` (страница Y, \"подано 1 марта 2023 г.\"), подтверждающие расхождение в сроках.\n\n---\n\n**Golden Dataset 3: Contradictory Dates/Documents (Противоречивые даты/документы)**\n\n*   **Сценарий:** Документы в одном и том же деле содержат противоречивую информацию, особенно касающуюся критических дат или фактов.\n*   **Цель:** Убедиться, что система может обнаруживать несоответствия между несколькими документами и отмечать их как риски.\n*   **Документы:**\n    *   `EmploymentContract_Version1_Dated_2020-01-01.pdf` (Дата начала: 1 января 2020 г.)\n    *   `EmploymentContract_Version2_Dated_2020-03-15.docx` (Дата начала: 15 марта 2020 г.)\n    *   `PromotionLetter_Dated_2022-06-01.pdf` (Ссылается на \"дату начала 1 января 2020 г.\")\n    *   `EmployeeRecord_Internal.txt` (Указывает дату начала: 1 февраля 2020 г.)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Finding(и)**, указывающие на противоречивые даты начала работы, с соответствующим уровнем `confidence`.\n    *   `Evidence`: Цитаты из `EmploymentContract_Version1_Dated_2020-01-01.pdf`, `EmploymentContract_Version2_Dated_2020-03-15.docx` и `EmployeeRecord_Internal.txt`, указывающие на конфликтующие даты.\n\n---\n\n**Golden Dataset 4: Incomplete Document Package (Отсутствующие критические документы)**\n\n*   **Сценарий:** Дело, в котором отсутствует критически важный документ (например, фактическое письмо об увольнении или ключевое доказательство, требуемое набором правил) из загруженных файлов.\n*   **Цель:** Убедиться, что система идентифицирует отсутствие ожидаемых документов или информации на основе применяемого набора правил и помечает это как процессуальное упущение.\n*   **Документы:**\n    *   `ComplaintForm_Submitted.pdf` (Ссылается на \"приложенное письмо об увольнении\")\n    *   `EmailCorrespondence.txt` (Обсуждается увольнение)\n    *   `WitnessStatement.pdf`\n    *   *Намеренно отсутствует: `DismissalLetter.pdf`*\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Finding**, указывающий на отсутствие критического документа (например, \"Письмо об увольнении упоминается, но не найдено\").\n    *   `Evidence`: Цитата из `ComplaintForm_Submitted.pdf` (страница X, \"См. приложенное письмо об увольнении...\") и из `EmailCorrespondence.txt` (\"Относительно вашего увольнения...\"), что косвенно указывает на отсутствие документа. `confidence` может быть средним, так как система выводит отсутствие, а не находит явный текст.\n\n---\n\n**Golden Dataset 5: Poor Scan / OCR Noise & Encoding Issues (Плохой скан / шум OCR и проблемы кодировки)**\n\n*   **Сценарий:** Документы с плохим качеством сканирования, рукописными заметками, водяными знаками или смешанными языками, что потенциально может привести к ошибкам OCR или неправильному извлечению текста. Также документы с необычной кодировкой или специальными символами.\n*   **Цель:**\n    *   Проверить надежность пайплайна OCR/Извлечения при работе с несовершенными входными данными.\n    *   Проверить корректную обработку ошибок и изящное снижение производительности, когда извлечение текста затруднено.\n    *   Убедиться, что даже при ошибках `Findings` по-прежнему имеют `Evidence` (даже если само evidence содержит ошибки OCR).\n    *   Проверить, что система не падает и не выдает некорректный вывод из-за проблем с кодировкой.\n*   **Документы:**\n    *   `HandwrittenNotes_LowResScan.jpg` (скан рукописных заметок низкого качества, потенциальные ошибки OCR)\n    *   `WatermarkedDoc_Scanned.pdf` (PDF с сильным водяным знаком, сложный для OCR)\n    *   `MixedLanguageContract_Scan.pdf` (сканированный контракт с английским и несколькими ирландскими/специальными символами)\n    *   `UTF8_with_Special_Chars.txt` (текстовый файл с различными символами Unicode и эмодзи)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified` или `Validated` (в зависимости от фактического содержимого и правил).\n    *   `Procedural Validation Report`: Может включать `Finding-и`, связанные с потенциальными проблемами извлечения данных, если правила настроены на их обнаружение. В противном случае, он должен отражать findings на основе *извлеченного* (потенциально ошибочного) текста.\n    *   **КРИТИЧНО:** Любой сгенерированный `Finding` **ОБЯЗАН** иметь `Evidence`, даже если процитированный `Evidence` содержит ошибки OCR. Система не должна \"галлюцинировать\" текст.\n    *   Система не должна падать или генерировать нечитаемые отчеты из-за проблем с кодировкой. `UTF8_with_Special_Chars.txt` должен быть обработан без повреждения данных.\n\n---\n\n### **3. Gate Checklist (Условия, когда релиз можно выпускать)**\n\nЭтот чек-лист представляет собой **абсолютно минимальные критерии**, при которых MVP может считаться \"готовым для внутреннего тестирования и потенциального выпуска\" (согласно DoD Бизнес-Аналитика) и, что более важно, \"готовым для подтверждения QA\". **Провал по любому пункту \"Блокера\" приводит к немедленной блокировке релиза.**\n\n---\n\n**I. Основная функциональность - Блокеры (Немедленная блокировка релиза)**\n\n*   **G-C-001 (Аутентификация пользователя):** Регистрация пользователя, подтверждение email и вход в систему полностью функциональны.\n*   **G-C-002 (Управление делами):** Пользователь может успешно создать новое дело (Case), просмотреть его на дашборде и перейти в его Workspace.\n*   **G-C-003 (Загрузка документов):** Пользователь может загружать все поддерживаемые типы документов (PDF, DOCX, TXT, JPG, PNG) с помощью Drag&Drop, и файлы отображаются в Workspace.\n*   **G-C-004 (Извлечение текста):** Текст успешно извлекается из ВСЕХ поддерживаемых типов документов (OCR для сканов/PDF, парсинг для DOCX/TXT). Документы показывают корректные статусы обработки.\n*   **G-C-005 (Инициирование Run):** Пользователь может инициировать \"Validation Run\" для дела, и статус дела меняется на \"Under Review\".\n*   **G-C-006 (Завершение пайплайна PVE):** Каждый инициированный Run завершает свой пайплайн (Intake → Under Review → Risks Identified/Validated) без сбоев или бесконечного зависания.\n*   **G-C-007 (Finding с Evidence - КРИТИЧНО!):** **КАЖДЫЙ `Finding`, сгенерированный в отчете, ИМЕЕТ соответствующий `Evidence` (doc_id, page, цитата/фрагмент, confidence). Любой `Finding` без `Evidence` является блокирующим дефектом.**\n*   **G-C-008 (Генерация отчета):** `Procedural Validation Report` успешно генерируется в форматах PDF и JSON по завершении Run.\n*   **G-C-009 (Просмотр/Экспорт отчета):** Пользователь может просмотреть PDF-отчет в UI и скачать обе версии (PDF и JSON).\n*   **G-C-0010 (GDPR - Purge):** Функция \"Удалить дело\" (Purge) полностью и безвозвратно удаляет ВСЕ связанные данные (документы, метаданные, извлеченный текст, embeddings, findings, записи аудита, относящиеся к делу) из ВСЕХ хранилищ (БД, S3/MinIO, векторная база). Это должно быть подтверждено проверкой данных.\n*   **G-C-011 (GDPR - Audit Log):** Критические действия (инициирование/завершение Run, загрузка/удаление документов, доступ к отчету) логируются в `Audit Log` согласно спецификации, БЕЗ PII.\n*   **G-C-012 (Дисклеймеры):** Отчет (PDF и JSON) явно отображает дисклеймер: \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\"\n\n---\n\n**II. Целостность и согласованность данных - Высокий приоритет**\n\n*   **G-DI-001 (Согласованность отчетов):** Семантическое содержимое, `Finding-и` и `Evidence` в `Report.pdf` согласованы и соответствуют `Report.json`.\n*   **G-DI-002 (Точность Evidence):** Процитированные фрагменты `Evidence` в отчете точно соответствуют тексту в ссылающихся `doc_id` и `page`. Отсутствие \"галлюцинаций\".\n*   **G-DI-003 (Трассируемость версий):** Каждый `Run` корректно ассоциирован с `run_id`, `ruleset_version` и `pipeline_version` в отчете и `Audit Log`.\n*   **G-DI-004 (Структурирование фактов):** Основные факты и временная шкала корректно извлекаются и отражаются во внутренней модели данных системы (проверяется через `Report.json` или отладочные интерфейсы, если доступны).\n\n---\n\n**III. Безопасность и комплаенс - Высокий приоритет**\n\n*   **G-SC-001 (RBAC - Базовый):** Пользователи могут получать доступ/управлять только теми делами, которыми они владеют или к которым им предоставлен доступ. (Для MVP сосредоточиться на разрешениях роли 'User').\n*   **G-SC-002 (Валидация файлов):** Загружаемые файлы проходят базовую валидацию MIME-типа и соблюдаются лимиты размера.\n*   **G-SC-003 (Шифрование данных в покое):** Данные в основном хранилище (S3/MinIO, Postgres) подтверждены как зашифрованные в покое (согласно спецификации архитектора/безопасности).\n*   **G-SC-004 (TLS):** Все сетевые соединения с платформой (UI, API) защищены с помощью TLS/HTTPS.\n\n---\n\n**IV. Производительность и стабильность - Средний приоритет (для MVP)**\n\n*   **G-PS-001 (Базовая отзывчивость):** Ключевые действия UI (например, загрузка дашборда, открытие Workspace) достаточно отзывчивы.\n*   **G-PS-002 (Надежность):** Система не падает и не становится неотзывчивой при обработке ожидаемой нагрузки для действий одного пользователя (например, загрузка большого PDF, запуск валидации).\n\n---\n\n**V. UX/UI - Средний приоритет (для MVP)**\n\n*   **G-UX-001 (Интуитивный поток):** Основные пользовательские пути (онбординг, создание дела, загрузка, запуск, отчет) интуитивно понятны и легки для навигации без значительных затруднений.\n*   **G-UX-002 (Четкость статусов):** Статусы дела и документа четко отображаются и обновляются в UI.\n\n---\n\n**VI. Покрытие тестами - Высокий приоритет**\n\n*   **G-TC-001 (Golden Datasets пройдены):** Все 5 `Golden Datasets` (Чистый кейс, Нарушение сроков, Противоречия, Отсутствующие документы, Плохой скан/кодировка) успешно выполнены, и их ожидаемые результаты (включая генерацию `Finding` и валидность `Evidence`) подтверждены.\n*   **G-TC-002 (Отсутствие критических ошибок):** Нет открытых ошибок блокирующей или критической серьезности для `Must-have` функционала.\n*   **G-TC-003 (Покрытие Unit/Integration):** Основные бэкенд-сервисы и API-эндпоинты имеют достаточное покрытие Unit и Integration тестами (например, >70% покрытие по строкам для критических модулей).\n\n---\n\n### **4. Regression Checklist (Что прогоняем каждый раз)**\n\nЭтот чек-лист детализирует набор тестов, которые должны выполняться при любых изменениях кода, исправлениях ошибок или развертывании новых функций для обеспечения стабильности системы и предотвращения регрессий. Он использует `Golden Datasets` и ключевые E2E сценарии.\n\n---\n\n**I. Критический смоук-тест и основная функциональность (Автоматизировано, запускается при каждом коммите/PR)**\n\n*   **R-001 (Аутентификация пользователя):**\n    *   Успешная регистрация и вход пользователя.\n    *   Вход с неверными учетными данными (ожидаемый провал).\n    *   Поведение сессии (валидность/обновление JWT-токена).\n*   **R-002 (Создание дела и дашборд):**\n    *   Создание нового дела (Case).\n    *   Просмотр нового дела на дашборде.\n    *   Переход в Workspace дела.\n*   **R-003 (Загрузка документов - Базовая):**\n    *   Загрузка одного небольшого PDF-файла.\n    *   Загрузка одного небольшого DOCX-файла.\n    *   Проверка отображения документа в Workspace.\n*   **R-004 (Инициирование Run PVE):**\n    *   Инициирование Validation Run для дела с документами.\n    *   Проверка изменения статуса дела на \"Under Review\".\n*   **R-005 (Доступность отчета):**\n    *   После завершения Run (мок или быстрый путь), проверка доступности отчета (PDF/JSON) для скачивания.\n*   **R-006 (GDPR Purge - Базовая):**\n    *   Удаление простого дела (проверка UI подтверждения и первичных проверок БД/хранилища).\n\n---\n\n**II. Выполнение Golden Datasets (Автоматизировано, запускается перед каждым релиз-кандидатом/крупным развертыванием)**\n\n*   **R-007 (Golden Dataset 1 - Чистый кейс):** Выполнить и проверить \"Procedurally Correct Case\" в соответствии с его ожидаемым результатом (отсутствие ложных срабатываний, статус `Validated`).\n*   **R-008 (Golden Dataset 2 - Нарушение сроков):** Выполнить и проверить \"Critical Timeline Violation\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректный `Finding` с `Evidence`).\n*   **R-009 (Golden Dataset 3 - Противоречивые даты):** Выполнить и проверить \"Contradictory Dates/Documents\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректные `Findings` с `Evidence`).\n*   **R-010 (Golden Dataset 4 - Отсутствующие документы):** Выполнить и проверить \"Incomplete Document Package\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректный `Finding` с `Evidence`).\n*   **R-011 (Golden Dataset 5 - Плохой скан/кодировка):** Выполнить и проверить \"Poor Scan / OCR Noise & Encoding Issues\" в соответствии с его ожидаемым результатом (стабильность системы, `Findings` с `Evidence` даже при зашумленном тексте, отсутствие сбоев из-за специальных символов).\n\n---\n\n**III. Целостность данных и комплаенс (Автоматизировано/Вручную, запускается перед каждым релиз-кандидатом)**\n\n*   **R-012 (Целостность Evidence):**\n    *   Автоматизировано: Случайно выбрать 10-20 `Finding-ов` из отчетов `Golden Datasets` и проверить программное соответствие `цитаты/фрагмента` `doc_id/page`.\n    *   Вручную: Визуально проверить критические `Finding-и` и `Evidence` в PDF-отчетах на точность и отсутствие \"галлюцинаций\".\n*   **R-013 (Согласованность отчетов):**\n    *   Автоматизировано: Сравнить ключевые данные `Finding` между `Report.pdf` и `Report.json` на согласованность.\n*   **R-014 (Проверка Audit Log):**\n    *   Автоматизировано: Проверить наличие записей в `Audit Log` о завершении `Run` для всех `Golden Dataset` runs.\n    *   Вручную: Выполнить загрузку документа и операцию purge, затем проверить `Audit Log` на наличие соответствующих записей (без PII).\n*   **R-015 (Полная проверка Purge):**\n    *   Вручную: Выполнить операцию `Purge` на выделенном тестовом кейсе. Затем попытаться получить данные (файлы из S3/MinIO, записи из БД, embeddings из векторной базы) с помощью прямых запросов/API, чтобы подтвердить полное удаление.\n\n---\n\n**IV. Пограничные случаи (Автоматизировано/Вручную, по мере необходимости в зависимости от изменений)**\n\n*   **R-016 (Пограничные случаи загрузки файлов):**\n    *   Загрузка файлов экстремально большого размера (до максимального лимита).\n    *   Загрузка файлов нулевого размера.\n    *   Попытка загрузки неподдерживаемых типов файлов (например, `.exe`, `.zip`).\n*   **R-017 (Пограничные случаи OCR/извлечения):**\n    *   Документы с необычной разметкой, таблицами, несколькими колонками.\n    *   Документы с повернутым текстом.\n    *   Документы с очень маленьким/большим размером шрифта.\n*   **R-018 (Пустой кейс/без документов):**\n    *   Попытка запустить валидацию для дела без документов. (Ожидается: конкретная ошибка/предупреждение).\n\n---\n\n**V. Пользовательские роли и разрешения (Вручную, запускается при изменении логики RBAC)**\n\n*   **R-019 (Роль \"Пользователь\"):** Проверить, что \"Пользователь\" может создавать, загружать, запускать, просматривать, экспортировать и удалять *свои собственные* дела.\n*   **R-020 (Роль \"Просмотрщик\" - если в MVP):** Проверить, что \"Просмотрщик\" может только просматривать назначенные ему дела и отчеты, но не может изменять, загружать, запускать или удалять их.\n\n---"
    },
    {
        "title": "QA Верификатор Baseline",
        "content": "Я, QA Верификатор проекта Irish Shepherd, внимательно изучил отчет Бизнес-Аналитика, общие требования Master Brief, архитектурные решения и все предоставленные спецификации. Основываясь на своем праве блокировать релиз и ключевом принципе **\"finding без evidence запрещён\"**, представляю обязательные артефакты для верификации готовности продукта BURAN PVE.\n\n---\n\n### **1. Test Plan (Unit/Integration/E2E + Регресс)**\n\n**Общая стратегия тестирования BURAN PVE:**\nНаш подход к тестированию будет многоуровневым и сфокусированным на обеспечении функциональной корректности, целостности данных, соблюдении требований комплаенса (GDPR) и базовой безопасности для MVP. Приоритет отдается автоматизации для повторяющихся и критических сценариев, а ручное тестирование будет применяться для проверки UX/UI и сложных исследовательских сценариев.\n\n**Типы тестов:**\n\n1.  **Unit Tests (Unit):**\n    *   **Цель:** Проверка корректности работы отдельных функций, методов и классов в изоляции.\n    *   **Область охвата:** Утилиты для извлечения текста (парсинг DOCX/TXT), функции оценки правил (Ruleset), обработчики API-эндпоинтов, методы ORM для взаимодействия с БД, компоненты пайплайна PVE (например, отдельные шаги структурирования фактов, генерация `Finding`/`Evidence`).\n    *   **Ответственность:** Разработчики.\n    *   **Покрытие:** Высокое для всей ключевой бизнес-логики и компонентов PVE.\n\n2.  **Integration Tests (Integration):**\n    *   **Цель:** Проверка взаимодействия между различными модулями или сервисами.\n    *   **Область охвата:** Связь между Backend и Database (Postgres), Backend и Storage (S3/MinIO), Backend и OCR Service, Backend и Policy/Ruleset Service. Проверка API-контрактов и корректности передачи данных (например, от OCR к PVE, от PVE к генерации отчета).\n    *   **Ответственность:** Разработчики, QA Инженеры.\n    *   **Фокус:** API-эндпоинты, персистентность данных, обработка сообщений в очереди (Worker/Queue), корректность вызовов внешних сервисов (с использованием моков или изолированных сред).\n\n3.  **End-to-End (E2E) Tests (E2E):**\n    *   **Цель:** Имитация полного пользовательского пути от начала до конца, включая взаимодействие с UI, обработку на бэкенде и персистентность данных.\n    *   **Область охвата (на основе User Flows из отчета БА):**\n        *   **Онбординг пользователя (US-001):** Регистрация → Подтверждение email → Логин → Выбор/создание организации (если применимо для MVP).\n        *   **Управление делом (US-002, US-003, US-004):** Создание дела → Загрузка документов (разных типов, размеров) (US-005) → Мониторинг статусов обработки документов (US-006).\n        *   **Процесс валидации (US-009):** Запуск валидации → Отслеживание изменения статуса дела (Under Review → Risks Identified/Validated) → Просмотр отчета (US-013).\n        *   **Работа с отчетом (US-013, US-014):** Просмотр PDF отчета в UI (проверка интерактивных элементов, ссылок на `Evidence`) → Скачивание PDF → Скачивание JSON.\n        *   **Удаление данных (Purge) (US-016):** Удаление дела с подтверждением → Верификация полного удаления данных из всех хранилищ (БД, S3/MinIO, векторная база).\n        *   **RBAC (базовый, US-018 если в MVP, иначе US-018):** Проверка доступа `User` к своим делам и отчетам.\n        *   **Audit Log (US-015):** Выполнение ключевых действий и проверка соответствующих записей в `Audit Log`.\n    *   **Ответственность:** QA Инженеры.\n\n4.  **Security Smoke Tests (Security Smoke):**\n    *   **Цель:** Проверка работоспособности критически важных механизмов безопасности.\n    *   **Область охвата (на основе Security Baseline БА):**\n        *   **Аутентификация/Авторизация:** Проверка входа с валидными/невалидными учетными данными, проверка сессий (JWT), доступ к ресурсам только по роли.\n        *   **Загрузка файлов (US-020):** Валидация MIME-типа, проверка лимитов размера, попытки загрузки исполняемых файлов или вредоносных скриптов.\n        *   **Шифрование:** Проверка использования TLS для всего трафика, подтверждение шифрования at-rest.\n        *   **Логирование (US-015):** Убедиться, что PII не попадает в производственные логи.\n    *   **Ответственность:** QA Инженеры, Специалист по Кибербезопасности.\n\n5.  **Regression Tests (Regression):**\n    *   **Цель:** Убедиться, что новые изменения или исправления ошибок не внесли новые дефекты и не привели к регрессии ранее работающей функциональности.\n    *   **Область охвата:** Критический набор Unit, Integration и E2E тестов, включая прогон `Golden Datasets`.\n    *   **Ответственность:** QA Инженеры (автоматизированные где возможно, ручные для сложных UI и критичной бизнес-логики).\n    *   **Частота:** Запуск перед каждым релиз-кандидатом и крупным развертыванием.\n\n**Подходы к тестированию:**\n\n*   **Автоматизация:** Приоритет для Unit, Integration, API, Security Smoke и критических E2E сценариев (регистрация, создание дела, запуск валидации, удаление дела). Используемые инструменты: Playwright/Selenium для E2E, pytest для Unit/Integration/API.\n*   **Ручное тестирование:** Необходим для оценки UX/UI, исследовательского тестирования, проверки сложных нюансов в отчетах (особенно интерпретации контента), а также для проверки доступности (accessibility).\n*   **Управление тестовыми данными:** Использование `Golden Datasets` для валидации пайплайна PVE. Создание синтетических тестовых данных для регистрации пользователей, создания дел и различных типов/размеров документов. Обеспечение изоляции данных для параллельного выполнения тестов.\n*   **Управление дефектами:** Четкое документирование дефектов с шагами воспроизведения, ожидаемым/фактическим результатом, скриншотами и логами. Приоритизация дефектов по критичности (Блокер, Критический, Значительный, Незначительный, Косметический) и влиянию.\n\n---\n\n### **2. Golden Datasets (Структура 5 тестовых пакетов документов)**\n\nЭти `Golden Datasets` предназначены для тщательной проверки основного пайплайна PVE и генерации отчетов, обеспечивая способность системы обрабатывать различные реальные сценарии, включая пограничные случаи. Каждый пакет включает описание сценария, ожидаемый результат и типы документов.\n\n**Общие требования ко всем Golden Datasets:**\n\n*   Каждый `Finding` в отчете **ОБЯЗАН** включать `doc_id`, `page`, `цитату/фрагмент` и `confidence`. **Finding без Evidence запрещён.**\n*   `Procedural Validation Report` (PDF и JSON) **ОБЯЗАН** содержать дисклеймер: \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\" (US-012.5)\n*   Содержимое `Report.pdf` и `Report.json` должно быть семантически согласованным (DoD 4.5).\n*   Записи в `Audit Log` для запуска и завершения `Run` **ОБЯЗАНЫ** генерироваться, включая `run_id`, `ruleset_version`, `model_version`, пользователя и временную метку (US-015.1).\n\n---\n\n**Golden Dataset 1: Procedurally Correct Case (Чистый кейс)**\n\n*   **Сценарий:** Простой случай с полным набором необходимых документов, предоставленных в срок и без видимых процессуальных нарушений.\n*   **Цель:** Убедиться, что система корректно определяет *отсутствие* процессуальных рисков или флагов, или выявляет только незначительные информационные флаги (например, \"все документы успешно обработаны\"). Это подтверждает отсутствие ложных срабатываний.\n*   **Документы:**\n    *   `EmploymentContract_Signed_Clean.pdf` (чистый, читаемый, четкие даты)\n    *   `ComplaintForm_Filed_Date_InTime.pdf` (явно указывает на подачу в течение 4 недель после увольнения)\n    *   `DismissalLetter_Dated_InTime.docx` (четкая дата увольнения)\n    *   `PaySlips_Last3Months_Standard.pdf` (стандартный формат, без расхождений)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Validated`.\n    *   `Procedural Validation Report`: Минимальное количество `Finding-ов`, связанных с рисками/несоответствиями, или их полное отсутствие. Если присутствуют, они должны быть информационными (например, \"Все документы в порядке\").\n    *   `Evidence`: Ни один `Finding` не должен быть сгенерирован без `Evidence`. Если `Finding-и` отсутствуют, `Evidence` не требуется.\n\n---\n\n**Golden Dataset 2: Critical Timeline Violation (Критическое нарушение сроков)**\n\n*   **Сценарий:** Дело, в котором критический срок (например, подача жалобы в течение определенного периода) был очевидно пропущен на основании предоставленных документов.\n*   **Цель:** Убедиться, что система точно идентифицирует и отмечает явное нарушение процессуальных сроков с высокой степенью уверенности.\n*   **Документы:**\n    *   `DismissalLetter_Dated_2023-01-01.pdf` (Дата увольнения: 1 января 2023 года)\n    *   `ComplaintSubmissionForm_Dated_2023-03-01.docx` (Дата подачи жалобы: 1 марта 2023 года. *Предполагается 4-недельный срок подачи в WRC в Ирландии по ирландским правилам, настроенным в `Ruleset`.*)\n    *   `EmailExchange_PriorDismissal.txt`\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Критический Finding**, указывающий на пропущенный срок, с высокой `confidence`.\n    *   Пример `Finding`: \"Потенциальное нарушение срока подачи жалобы в WRC (превышен 4-недельный лимит).\"\n    *   `Evidence`: Прямые цитаты из `DismissalLetter_Dated_2023-01-01.pdf` (страница X, \"уволен 1 января 2023 г.\") и `ComplaintSubmissionForm_Dated_2023-03-01.docx` (страница Y, \"подано 1 марта 2023 г.\"), подтверждающие расхождение в сроках.\n\n---\n\n**Golden Dataset 3: Contradictory Dates/Documents (Противоречивые даты/документы)**\n\n*   **Сценарий:** Документы в одном и том же деле содержат противоречивую информацию, особенно касающуюся критических дат или фактов.\n*   **Цель:** Убедиться, что система может обнаруживать несоответствия между несколькими документами и отмечать их как риски.\n*   **Документы:**\n    *   `EmploymentContract_Version1_Dated_2020-01-01.pdf` (Дата начала: 1 января 2020 г.)\n    *   `EmploymentContract_Version2_Dated_2020-03-15.docx` (Дата начала: 15 марта 2020 г.)\n    *   `PromotionLetter_Dated_2022-06-01.pdf` (Ссылается на \"дату начала 1 января 2020 г.\")\n    *   `EmployeeRecord_Internal.txt` (Указывает дату начала: 1 февраля 2020 г.)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Finding(и)**, указывающие на противоречивые даты начала работы, с соответствующим уровнем `confidence`.\n    *   `Evidence`: Цитаты из `EmploymentContract_Version1_Dated_2020-01-01.pdf`, `EmploymentContract_Version2_Dated_2020-03-15.docx` и `EmployeeRecord_Internal.txt`, указывающие на конфликтующие даты.\n\n---\n\n**Golden Dataset 4: Incomplete Document Package (Отсутствующие критические документы)**\n\n*   **Сценарий:** Дело, в котором отсутствует критически важный документ (например, фактическое письмо об увольнении или ключевое доказательство, требуемое набором правил) из загруженных файлов.\n*   **Цель:** Убедиться, что система идентифицирует отсутствие ожидаемых документов или информации на основе применяемого набора правил и помечает это как процессуальное упущение.\n*   **Документы:**\n    *   `ComplaintForm_Submitted.pdf` (Ссылается на \"приложенное письмо об увольнении\")\n    *   `EmailCorrespondence.txt` (Обсуждается увольнение)\n    *   `WitnessStatement.pdf`\n    *   *Намеренно отсутствует: `DismissalLetter.pdf`*\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified`.\n    *   `Procedural Validation Report`: **Finding**, указывающий на отсутствие критического документа (например, \"Письмо об увольнении упоминается, но не найдено в деле\").\n    *   `Evidence`: Цитата из `ComplaintForm_Submitted.pdf` (страница X, \"См. приложенное письмо об увольнении...\") и из `EmailCorrespondence.txt` (\"Относительно вашего увольнения...\"), что косвенно указывает на отсутствие документа. `confidence` может быть средним, так как система выводит отсутствие, а не находит явный текст.\n\n---\n\n**Golden Dataset 5: Poor Scan / OCR Noise & Encoding Issues (Плохой скан / шум OCR и проблемы кодировки)**\n\n*   **Сценарий:** Документы с плохим качеством сканирования, рукописными заметками, водяными знаками или смешанными языками, что потенциально может привести к ошибкам OCR или неправильному извлечению текста. Также документы с необычной кодировкой или специальными символами.\n*   **Цель:**\n    *   Проверить надежность пайплайна OCR/Извлечения при работе с несовершенными входными данными.\n    *   Проверить корректную обработку ошибок и изящное снижение производительности, когда извлечение текста затруднено.\n    *   Убедиться, что даже при ошибках `Findings` по-прежнему имеют `Evidence` (даже если само evidence содержит ошибки OCR).\n    *   Проверить, что система не падает и не выдает некорректный вывод из-за проблем с кодировкой.\n*   **Документы:**\n    *   `HandwrittenNotes_LowResScan.jpg` (скан рукописных заметок низкого качества, потенциальные ошибки OCR)\n    *   `WatermarkedDoc_Scanned.pdf` (PDF с сильным водяным знаком, сложный для OCR)\n    *   `MixedLanguageContract_Scan.pdf` (сканированный контракт с английским и несколькими ирландскими/специальными символами)\n    *   `UTF8_with_Special_Chars.txt` (текстовый файл с различными символами Unicode и эмодзи)\n*   **Ожидаемый результат:**\n    *   Статус дела: `Risks Identified` или `Validated` (в зависимости от фактического содержимого и правил).\n    *   `Procedural Validation Report`: Может включать `Finding-и`, связанные с потенциальными проблемами извлечения данных, если правила настроены на их обнаружение. В противном случае, он должен отражать findings на основе *извлеченного* (потенциально ошибочного) текста.\n    *   **КРИТИЧНО:** Любой сгенерированный `Finding` **ОБЯЗАН** иметь `Evidence`, даже если процитированный `Evidence` содержит ошибки OCR. Система не должна \"галлюцинировать\" текст.\n    *   Система не должна падать или генерировать нечитаемые отчеты из-за проблем с кодировкой. `UTF8_with_Special_Chars.txt` должен быть обработан без повреждения данных.\n\n---\n\n### **3. Gate Checklist (Условия, когда релиз можно выпускать)**\n\nЭтот чек-лист представляет собой **абсолютно минимальные критерии**, при которых MVP может считаться \"готовым для внутреннего тестирования и потенциального выпуска\" (согласно DoD Бизнес-Аналитика) и, что более важно, \"готовым для подтверждения QA\". **Провал по любому пункту \"Блокера\" приводит к немедленной блокировке релиза.**\n\n---\n\n**I. Основная функциональность - БЛОКЕРЫ (Немедленная блокировка релиза)**\n\n*   **G-C-001 (Аутентификация пользователя - US-001):** Регистрация пользователя, подтверждение email и вход в систему полностью функциональны.\n*   **G-C-002 (Управление делами - US-002, US-003):** Пользователь может успешно создать новое дело (Case), просмотреть его на дашборде и перейти в его Workspace.\n*   **G-C-003 (Загрузка документов - US-005):** Пользователь может загружать все поддерживаемые типы документов (PDF, DOCX, TXT, JPG, PNG) с помощью Drag&Drop, и файлы отображаются в Workspace.\n*   **G-C-004 (Извлечение текста - US-007):** Текст успешно извлекается из ВСЕХ поддерживаемых типов документов (OCR для сканов/PDF, парсинг для DOCX/TXT). Документы показывают корректные статусы обработки (US-006).\n*   **G-C-005 (Инициирование Run - US-009):** Пользователь может инициировать \"Validation Run\" для дела, и статус дела меняется на \"Under Review\".\n*   **G-C-006 (Завершение пайплайна PVE - DoD 3.2):** Каждый инициированный Run завершает свой пайплайн (Intake → Under Review → Risks Identified/Validated) без сбоев или бесконечного зависания.\n*   **G-C-007 (Finding с Evidence - КРИТИЧНО! US-011, DoD 3.4):** **КАЖДЫЙ `Finding`, сгенерированный в отчете, ИМЕЕТ соответствующий `Evidence` (doc_id, page, цитата/фрагмент, confidence). ЛЮБОЙ `Finding` БЕЗ `Evidence` является БЛОКИРУЮЩИМ ДЕФЕКТОМ.**\n*   **G-C-008 (Генерация отчета - US-012):** `Procedural Validation Report` успешно генерируется в форматах PDF и JSON по завершении Run.\n*   **G-C-009 (Просмотр/Экспорт отчета - US-013, US-014):** Пользователь может просмотреть PDF-отчет в UI и скачать обе версии (PDF и JSON).\n*   **G-C-010 (GDPR - Purge - US-016, DoD 5.1):** Функция \"Удалить дело\" (Purge) полностью и безвозвратно удаляет ВСЕ связанные данные (документы, метаданные, извлеченный текст, embeddings, findings, записи аудита, относящиеся к делу) из ВСЕХ хранилищ (БД, S3/MinIO, векторная база). Это должно быть подтверждено проверкой данных.\n*   **G-C-011 (GDPR - Audit Log - US-015, DoD 5.3):** Критические действия (инициирование/завершение Run, загрузка/удаление документов, доступ к отчету) логируются в `Audit Log` согласно спецификации, БЕЗ PII.\n*   **G-C-012 (Дисклеймеры - US-012.5, DoD 4.6):** Отчет (PDF и JSON) явно отображает дисклеймер: \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\"\n\n---\n\n**II. Целостность и согласованность данных - Высокий приоритет**\n\n*   **G-DI-001 (Согласованность отчетов - DoD 4.5):** Семантическое содержимое, `Finding-и` и `Evidence` в `Report.pdf` согласованы и соответствуют `Report.json`.\n*   **G-DI-002 (Точность Evidence - QA Принцип):** Процитированные фрагменты `Evidence` в отчете точно соответствуют тексту в ссылающихся `doc_id` и `page`. Отсутствие \"галлюцинаций\" или выдуманного текста.\n*   **G-DI-003 (Трассируемость версий - US-017, DoD 4.4, DoD 6.1):** Каждый `Run` корректно ассоциирован с `run_id`, `ruleset_version` и `pipeline_version` в отчете и `Audit Log`.\n*   **G-DI-004 (Структурирование фактов - US-008):** Основные факты и временная шкала корректно извлекаются и отражаются во внутренней модели данных системы (проверяется через `Report.json` или отладочные интерфейсы, если доступны).\n\n---\n\n**III. Безопасность и комплаенс - Высокий приоритет**\n\n*   **G-SC-001 (RBAC - Базовый - БА User Roles):** Пользователи могут получать доступ/управлять только теми делами, которыми они владеют или к которым им предоставлен доступ. (Для MVP сосредоточиться на разрешениях роли 'User').\n*   **G-SC-002 (Валидация файлов - US-020):** Загружаемые файлы проходят базовую валидацию MIME-типа и соблюдаются лимиты размера.\n*   **G-SC-003 (Шифрование данных в покое - БА Security Baseline):** Данные в основном хранилище (S3/MinIO, Postgres) подтверждены как зашифрованные в покое (согласно спецификации архитектора/безопасности).\n*   **G-SC-004 (TLS - БА Security Baseline):** Все сетевые соединения с платформой (UI, API) защищены с помощью TLS/HTTPS.\n\n---\n\n**IV. Производительность и стабильность - Средний приоритет (для MVP)**\n\n*   **G-PS-001 (Базовая отзывчивость - DoD 7.1):** Ключевые действия UI (например, загрузка дашборда, открытие Workspace) достаточно отзывчивы.\n*   **G-PS-002 (Надежность):** Система не падает и не становится неотзывчивой при обработке ожидаемой нагрузки для действий одного пользователя (например, загрузка большого PDF, запуск валидации).\n\n---\n\n**V. UX/UI - Средний приоритет (для MVP)**\n\n*   **G-UX-001 (Интуитивный поток - DoD 7.1):** Основные пользовательские пути (онбординг, создание дела, загрузка, запуск, отчет) интуитивно понятны и легки для навигации без значительных затруднений.\n*   **G-UX-002 (Четкость статусов - DoD 7.2):** Статусы дела и документа четко отображаются и обновляются в UI.\n\n---\n\n**VI. Покрытие тестами - Высокий приоритет**\n\n*   **G-TC-001 (Golden Datasets пройдены - DoD 8.2):** Все 5 `Golden Datasets` (Чистый кейс, Нарушение сроков, Противоречия, Отсутствующие документы, Плохой скан/кодировка) успешно выполнены, и их ожидаемые результаты (включая генерацию `Finding` и валидность `Evidence`) подтверждены.\n*   **G-TC-002 (Отсутствие критических ошибок - DoD 8.3):** Нет открытых ошибок блокирующей или критической серьезности для `Must-have` функционала.\n*   **G-TC-003 (Покрытие Unit/Integration - DoD 8.1):** Основные бэкенд-сервисы и API-эндпоинты имеют достаточное покрытие Unit и Integration тестами (например, >70% покрытие по строкам для критических модулей).\n\n---\n\n### **4. Regression Checklist (Что прогоняем каждый раз)**\n\nЭтот чек-лист детализирует набор тестов, которые должны выполняться при любых изменениях кода, исправлениях ошибок или развертывании новых функций для обеспечения стабильности системы и предотвращения регрессий. Он использует `Golden Datasets` и ключевые E2E сценарии.\n\n---\n\n**I. Критический смоук-тест и основная функциональность (Автоматизировано, запускается при каждом коммите/PR)**\n\n*   **R-001 (Аутентификация пользователя - US-001):**\n    *   Успешная регистрация и вход пользователя.\n    *   Вход с неверными учетными данными (ожидаемый провал).\n    *   Поведение сессии (валидность/обновление JWT-токена).\n*   **R-002 (Создание дела и дашборд - US-002, US-003):**\n    *   Создание нового дела (Case).\n    *   Просмотр нового дела на дашборде.\n    *   Переход в Workspace дела.\n*   **R-003 (Загрузка документов - Базовая - US-005):**\n    *   Загрузка одного небольшого PDF-файла.\n    *   Загрузка одного небольшого DOCX-файла.\n    *   Проверка отображения документа в Workspace.\n    *   Проверка статуса обработки (US-006).\n*   **R-004 (Инициирование Run PVE - US-009):**\n    *   Инициирование Validation Run для дела с документами.\n    *   Проверка изменения статуса дела на \"Under Review\" (US-009.2).\n*   **R-005 (Доступность отчета - US-013, US-014):**\n    *   После завершения Run (мок или быстрый путь), проверка доступности отчета (PDF/JSON) для скачивания.\n*   **R-006 (GDPR Purge - Базовая - US-016):**\n    *   Удаление простого дела (проверка UI подтверждения и первичных проверок БД/хранилища на отсутствие записей).\n\n---\n\n**II. Выполнение Golden Datasets (Автоматизировано, запускается перед каждым релиз-кандидатом/крупным развертыванием)**\n\n*   **R-007 (Golden Dataset 1 - Чистый кейс):** Выполнить и проверить \"Procedurally Correct Case\" в соответствии с его ожидаемым результатом (отсутствие ложных срабатываний, статус `Validated`).\n*   **R-008 (Golden Dataset 2 - Нарушение сроков):** Выполнить и проверить \"Critical Timeline Violation\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректный `Finding` с `Evidence`).\n*   **R-009 (Golden Dataset 3 - Противоречивые даты):** Выполнить и проверить \"Contradictory Dates/Documents\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректные `Findings` с `Evidence`).\n*   **R-010 (Golden Dataset 4 - Отсутствующие документы):** Выполнить и проверить \"Incomplete Document Package\" в соответствии с его ожидаемым результатом (`Risks Identified`, корректный `Finding` с `Evidence`).\n*   **R-011 (Golden Dataset 5 - Плохой скан/кодировка):** Выполнить и проверить \"Poor Scan / OCR Noise & Encoding Issues\" в соответствии с его ожидаемым результатом (стабильность системы, `Findings` с `Evidence` даже при зашумленном тексте, отсутствие сбоев из-за специальных символов).\n\n---\n\n**III. Целостность данных и комплаенс (Автоматизировано/Вручную, запускается перед каждым релиз-кандидатом)**\n\n*   **R-012 (Целостность Evidence - US-011):**\n    *   Автоматизировано: Случайно выбрать 10-20 `Finding-ов` из отчетов `Golden Datasets` и проверить программное соответствие `цитаты/фрагмента` `doc_id/page`.\n    *   Вручную: Визуально проверить критические `Finding-и` и `Evidence` в PDF-отчетах на точность и отсутствие \"галлюцинаций\".\n*   **R-013 (Согласованность отчетов - DoD 4.5):**\n    *   Автоматизировано: Сравнить ключевые данные `Finding` между `Report.pdf` и `Report.json` на согласованность.\n*   **R-014 (Проверка Audit Log - US-015):**\n    *   Автоматизировано: Проверить наличие записей в `Audit Log` о завершении `Run` для всех `Golden Dataset` runs.\n    *   Вручную: Выполнить загрузку документа и операцию purge, затем проверить `Audit Log` на наличие соответствующих записей (без PII).\n*   **R-015 (Полная проверка Purge - US-016):**\n    *   Вручную: Выполнить операцию `Purge` на выделенном тестовом кейсе. Затем попытаться получить данные (файлы из S3/MinIO, записи из БД, embeddings из векторной базы) с помощью прямых запросов/API, чтобы подтвердить полное удаление.\n\n---\n\n**IV. Пограничные случаи (Автоматизировано/Вручную, по мере необходимости в зависимости от изменений)**\n\n*   **R-016 (Пограничные случаи загрузки файлов - US-005, US-020):**\n    *   Загрузка файлов экстремально большого размера (до максимального лимита).\n    *   Загрузка файлов нулевого размера.\n    *   Попытка загрузки неподдерживаемых типов файлов (например, `.exe`, `.zip`).\n*   **R-017 (Пограничные случаи OCR/извлечения - US-007):**\n    *   Документы с необычной разметкой, таблицами, несколькими колонками.\n    *   Документы с повернутым текстом.\n    *   Документы с очень маленьким/большим размером шрифта.\n*   **R-018 (Пустой кейс/без документов):**\n    *   Попытка запустить валидацию для дела без документов. (Ожидается: конкретная ошибка/предупреждение в UI).\n\n---\n\n**V. Пользовательские роли и разрешения (Вручную, запускается при изменении логики RBAC, US-018/БА User Roles)**\n\n*   **R-019 (Роль \"Пользователь\"):** Проверить, что \"Пользователь\" может создавать, загружать, запускать, просматривать, экспортировать и удалять *свои собственные* дела.\n*   **R-020 (Роль \"Просмотрщик\" - если в MVP):** Проверить, что \"Просмотрщик\" может только просматривать назначенные ему дела и отчеты, но не может изменять, загружать, запускать или удалять их.\n\n---"
    },
    {
        "title": "Старший Программист Baseline",
        "content": "Как Старший Программист, я принимаю эти требования и обязуюсь реализовать MVP Sprints 1-4, основываясь на Архитектуре v1.3, Master Spec от Бизнес-Аналитика и жестких критериях QA Верификатора, особенно уделяя внимание принципу **\"Finding без Evidence запрещён\"**.\n\nМоя задача — предоставить не только структуру, но и ключевые фрагменты логики и кода, которые демонстрируют понимание и реализацию основных требований.\n\n---\n\n## Реализация MVP Sprint 1-4: Проект BURAN PVE\n\n**Выбранные Технологии и Инструменты:**\n\n*   **Backend Framework:** FastAPI (Python)\n*   **Database:** PostgreSQL\n*   **ORM:** SQLAlchemy 2.0+ с Pydantic для моделей данных\n*   **Database Migrations:** Alembic\n*   **Asynchronous Tasks/Queue:** Celery с Redis (как брокер и бэкенд для результатов)\n*   **Object Storage:** MinIO (S3-совместимое хранилище)\n*   **OCR/Text Extraction:** `PyPDF` (для PDF), `python-docx` (для DOCX), `pytesseract` (для OCR сканов JPG/PNG)\n*   **NLP/Fact Extraction:** `spaCy` (базовое извлечение сущностей, таймлайн)\n*   **Report Generation:** `Jinja2` (шаблонизация) + `WeasyPrint` (HTML to PDF)\n*   **Authentication:** JWT (JSON Web Tokens)\n*   **Testing:** `pytest` (Unit/Integration), `httpx` (API), `Playwright` (E2E, для Golden Datasets)\n\n---\n\n### **1. Структура файлов проекта**\n\nСтруктура проекта будет модульной и легко расширяемой, отражая сервисный подход.\n\n```\nburan-pve/\n├── app/\n│   ├── api/                      # FastAPI API endpoints\n│   │   ├── v1/                   # Versioned API\n│   │   │   ├── auth.py           # US-001: Регистрация, логин, токены\n│   │   │   ├── cases.py          # US-002, US-003, US-004, US-016: Case CRUD\n│   │   │   ├── documents.py      # US-005, US-006: Загрузка, статус документов\n│   │   │   ├── pve_runs.py       # US-009: Запуск валидации, US-013, US-014: Отчеты\n│   │   │   └── users.py          # US-018: Управление пользователями (если в MVP), роли\n│   │   ├── __init__.py\n│   │   └── dependencies.py       # Зависимости для FastAPI (Auth, DB session, RBAC)\n│   ├── core/                     # Core utilities and configurations\n│   │   ├── config.py             # Настройки приложения из .env\n│   │   ├── security.py           # Хеширование, JWT, RBAC логика\n│   │   ├── exceptions.py         # Кастомные исключения\n│   │   ├── schemas.py            # Pydantic модели для запросов/ответов\n│   │   └── __init__.py\n│   ├── db/                       # Database layer\n│   │   ├── models.py             # SQLAlchemy ORM модели (Organization, User, Case, Document, Run, Finding, Evidence, AuditLog)\n│   │   ├── session.py            # Инициализация DB session\n│   │   ├── crud.py               # Функции для взаимодействия с DB (CRUD)\n│   │   └── __init__.py\n│   ├── services/                 # Business logic services\n│   │   ├── auth_service.py       # Аутентификация/Авторизация\n│   │   ├── case_service.py       # Управление делами\n│   │   ├── document_service.py   # Загрузка документов, метаданные\n│   │   ├── ocr_service.py        # US-007: OCR и извлечение текста\n│   │   ├── pve_service.py        # US-008, US-010, US-011: PVE Pipeline (структурирование, правила, Finding/Evidence)\n│   │   ├── report_service.py     # US-012: Генерация PDF/JSON отчетов\n│   │   ├── storage_service.py    # Взаимодействие с MinIO/S3\n│   │   ├── audit_service.py      # US-015: Запись в AuditLog\n│   │   ├── email_service.py      # US-001.2: Отправка email (мок для MVP)\n│   │   └── __init__.py\n│   ├── tasks/                    # Celery asynchronous tasks\n│   │   ├── celery.py             # Настройка Celery\n│   │   ├── document_tasks.py     # US-007: Задачи для OCR/извлечения\n│   │   ├── pve_tasks.py          # US-009: Задачи для выполнения PVE\n│   │   └── __init__.py\n│   ├── static/                   # Статические файлы (например, шаблоны отчетов, дисклеймеры)\n│   ├── main.py                   # Главное приложение FastAPI\n│   └── __init__.py\n├── alembic/                      # Миграции базы данных (generated by Alembic)\n├── tests/\n│   ├── unit/                     # Unit тесты\n│   ├── integration/              # Интеграционные тесты\n│   ├── e2e/                      # E2E тесты (включая тестирование Golden Datasets через Playwright)\n│   ├── security/                 # Security smoke tests\n│   ├── golden_datasets/          # Файлы Golden Datasets и ожидаемые результаты\n│   ├── conftest.py               # Фикстуры для тестов\n│   └── test_main.py\n├── scripts/                      # Вспомогательные скрипты\n│   ├── run_dev.sh                # Запуск локальной dev-среды (docker-compose)\n│   ├── setup_db.sh               # Настройка БД и применение миграций\n│   └── seed_data.py              # Заполнение тестовыми данными\n├── .env.example                  # Пример файла переменных окружения\n├── Dockerfile                    # Для контейнеризации приложения\n├── docker-compose.yml            # Для локальной dev-среды (FastAPI, Postgres, Redis, MinIO, Celery)\n├── requirements.txt              # Зависимости Python\n├── README.md\n└── LICENSE\n```\n\n---\n\n### **2. Логика Аутентификации (Auth Logic)**\n\n**Покрытие US:** US-001 (Регистрация/логин), US-001.2 (подтверждение email), US-001.3 (логин после подтверждения), US-001.4 (сессии), US-015 (логирование), Базовая RBAC (UserRole).\n\n**Основные принципы:**\n*   **Безопасность паролей:** Всегда хешировать пароли с использованием `Bcrypt`.\n*   **Токены:** Использование JWT (Access и Refresh токены) для аутентификации и авторизации.\n*   **Подтверждение Email:** Пользователь должен подтвердить свой email перед полноценным использованием системы.\n*   **RBAC:** Роли (`ADMIN`, `ORG_OWNER`, `USER`, `VIEWER`) определяются на уровне пользователя и проверяются при доступе к ресурсам.\n\n**Ключевые фрагменты кода:**\n\n**`app/core/security.py`**\n```python\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Optional\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\n\nfrom app.core.config import settings\nfrom app.core.exceptions import AuthException\nfrom app.db.models import User, UserRole # Предполагаем, что UserRole - Enum\n\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"/api/v1/auth/login\")\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    return pwd_context.verify(plain_password, hashed_password)\n\ndef get_password_hash(password: str) -> str:\n    return pwd_context.hash(password)\n\ndef create_jwt_token(data: dict, token_type: str, expires_delta: Optional[timedelta] = None) -> str:\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.now(timezone.utc) + expires_delta\n    else:\n        # Устанавливаем разные дефолтные сроки для разных типов токенов\n        if token_type == \"access\":\n            expire = datetime.now(timezone.utc) + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n        elif token_type == \"refresh\":\n            expire = datetime.now(timezone.utc) + timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS)\n        elif token_type == \"email_verify\":\n            expire = datetime.now(timezone.utc) + timedelta(hours=settings.EMAIL_VERIFY_TOKEN_EXPIRE_HOURS)\n        else:\n            raise ValueError(\"Unknown token type\")\n            \n    to_encode.update({\"exp\": expire, \"sub\": token_type})\n    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\ndef decode_token(token: str) -> dict:\n    try:\n        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n        return payload\n    except JWTError:\n        raise AuthException(detail=\"Could not validate credentials\", status_code=401)\n\n# FastAPI Dependency для получения текущего пользователя\nasync def get_current_user(token: str = Depends(oauth2_scheme), db: 'Session' = Depends(lambda: None)): # db dependency will be injected by FastAPI\n    from app.db.crud import get_user_by_id # Импорт внутри для избежания цикличных зависимостей\n\n    try:\n        payload = decode_token(token)\n        user_id: int = payload.get(\"id\")\n        token_sub = payload.get(\"sub\")\n        if user_id is None or token_sub != \"access\":\n            raise AuthException(\"Invalid token payload or type\")\n    except AuthException as e:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=e.detail,\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    \n    # db here is a placeholder. In actual dependency chain, get_db() will be called first.\n    # For standalone testability or when used in `main.py` without DB, this default helps.\n    if db is None: # This block is for conceptual clarity, actual implementation would get a valid db session\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Database session not available for user retrieval.\"\n        )\n\n    user = get_user_by_id(db, user_id=user_id)\n    if user is None:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"User not found\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    if not user.is_verified: # US-001.3\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Email not verified. Please check your inbox for verification link.\",\n        )\n    return user\n\n# FastAPI Dependency для проверки роли\ndef require_role(roles: list[UserRole]):\n    def role_verifier(current_user: User = Depends(get_current_user)):\n        if current_user.role not in roles:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Not enough permissions\"\n            )\n        return current_user # Возвращаем пользователя для удобства\n    return role_verifier\n```\n\n**`app/db/models.py` (сущности `User`, `Organization`)**\n```python\nimport enum\nfrom sqlalchemy import Column, Integer, String, Boolean, DateTime, ForeignKey, Text, Enum\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import func\n\nBase = declarative_base()\n\nclass UserRole(enum.Enum):\n    ADMIN = \"admin\"\n    ORG_OWNER = \"org_owner\"\n    USER = \"user\"\n    VIEWER = \"viewer\"\n\nclass Organization(Base):\n    __tablename__ = \"organizations\"\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, unique=True, index=True, nullable=False)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n\n    users = relationship(\"User\", back_populates=\"organization\")\n    cases = relationship(\"Case\", back_populates=\"organization\")\n\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(Integer, primary_key=True, index=True)\n    email = Column(String, unique=True, index=True, nullable=False)\n    hashed_password = Column(String, nullable=False)\n    is_active = Column(Boolean, default=True)\n    is_verified = Column(Boolean, default=False) # US-001.2\n    role = Column(Enum(UserRole), default=UserRole.USER, nullable=False)\n    organization_id = Column(Integer, ForeignKey(\"organizations.id\"), nullable=True) # US-001.4 (потенциально)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n\n    organization = relationship(\"Organization\", back_populates=\"users\")\n    cases = relationship(\"Case\", back_populates=\"owner\")\n    audit_logs = relationship(\"AuditLog\", back_populates=\"user\") # US-015\n```\n\n**`app/api/v1/auth.py` (эндпоинты)**\n```python\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordRequestForm\nfrom sqlalchemy.orm import Session\n\nfrom app.core.config import settings\nfrom app.core.security import get_password_hash, verify_password, create_jwt_token, decode_token\nfrom app.core.schemas import UserCreate, Token, UserPublic, Message\nfrom app.db.crud import create_user, get_user_by_email, get_user_by_id, update_user # Заменить на update_user_is_verified\nfrom app.db.session import get_db\nfrom app.db.models import UserRole\nfrom app.services.audit_service import log_action\nfrom app.services.email_service import send_verification_email # Mock для MVP\n\nrouter = APIRouter()\n\n@router.post(\"/register\", response_model=UserPublic, status_code=status.HTTP_201_CREATED)\nasync def register_user_endpoint(user_in: UserCreate, db: Session = Depends(get_db)):\n    # US-001.1: Регистрация\n    db_user = get_user_by_email(db, email=user_in.email)\n    if db_user:\n        raise HTTPException(status_code=400, detail=\"Email already registered\")\n    \n    hashed_password = get_password_hash(user_in.password)\n    user = create_user(db, email=user_in.email, hashed_password=hashed_password, role=UserRole.USER, is_verified=False) # US-001.2\n    \n    # Отправка письма для подтверждения email (US-001.2)\n    verification_token = create_jwt_token(data={\"id\": user.id, \"email\": user.email}, token_type=\"email_verify\")\n    # В реальной системе тут был бы домен фронтенда: f\"{settings.FRONTEND_URL}/verify-email?token={verification_token}\"\n    verification_link = f\"{settings.BACKEND_URL}/api/v1/auth/confirm-email?token={verification_token}\"\n    send_verification_email(user.email, verification_link) # Mock call\n    \n    log_action(db, user_id=user.id, action=\"user_registered\", details={\"email\": user.email})\n    return user\n\n@router.post(\"/login\", response_model=Token)\nasync def login_for_access_token_endpoint(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):\n    # US-001.3: Логин\n    user = get_user_by_email(db, email=form_data.username)\n    if not user or not verify_password(form_data.password, user.hashed_password):\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect email or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    if not user.is_verified: # US-001.3\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN, \n            detail=\"Email not verified. Please check your inbox for verification link.\"\n        )\n    \n    access_token = create_jwt_token(\n        data={\"id\": user.id, \"role\": user.role.value, \"organization_id\": user.organization_id}, \n        token_type=\"access\"\n    )\n    refresh_token = create_jwt_token(\n        data={\"id\": user.id, \"role\": user.role.value, \"organization_id\": user.organization_id}, \n        token_type=\"refresh\"\n    )\n    \n    log_action(db, user_id=user.id, action=\"user_logged_in\")\n    return {\"access_token\": access_token, \"token_type\": \"bearer\", \"refresh_token\": refresh_token}\n\n@router.get(\"/confirm-email\", response_model=Message)\nasync def confirm_email_endpoint(token: str, db: Session = Depends(get_db)):\n    # US-001.2: Подтверждение email\n    try:\n        payload = decode_token(token)\n        user_id = payload.get(\"id\")\n        token_sub = payload.get(\"sub\")\n        if token_sub != \"email_verify\":\n            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid token type.\")\n        \n        user = get_user_by_id(db, user_id=user_id)\n        if not user:\n            raise HTTPException(status_code=404, detail=\"User not found.\")\n        if user.is_verified:\n            return {\"message\": \"Email already verified.\"}\n        \n        user.is_verified = True # Предполагаем, что crud.update_user умеет обновлять поля\n        db.add(user)\n        db.commit()\n        db.refresh(user)\n        \n        log_action(db, user_id=user.id, action=\"email_verified\")\n        return {\"message\": \"Email successfully verified! You can now log in.\"}\n    except JWTError:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid or expired verification token.\")\n\n@router.post(\"/refresh-token\", response_model=Token)\nasync def refresh_access_token_endpoint(refresh_token: str, db: Session = Depends(get_db)):\n    # US-001.4: Обновление Access-токена с помощью Refresh-токена\n    try:\n        payload = decode_token(refresh_token)\n        user_id = payload.get(\"id\")\n        token_sub = payload.get(\"sub\")\n        if token_sub != \"refresh\":\n            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Invalid token type for refresh.\")\n        \n        user = get_user_by_id(db, user_id=user_id)\n        if not user:\n            raise HTTPException(status_code=404, detail=\"User not found.\")\n        \n        new_access_token = create_jwt_token(\n            data={\"id\": user.id, \"role\": user.role.value, \"organization_id\": user.organization_id}, \n            token_type=\"access\"\n        )\n        log_action(db, user_id=user.id, action=\"access_token_refreshed\")\n        return {\"access_token\": new_access_token, \"token_type\": \"bearer\", \"refresh_token\": refresh_token}\n    except JWTError:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid or expired refresh token.\", headers={\"WWW-Authenticate\": \"Bearer\"})\n```\n\n---\n\n### **3. Case CRUD Logic**\n\n**Покрытие US:** US-002 (Дашборд), US-003 (Создание), US-004 (Workspace, статус), US-016 (Удаление/Purge), US-015 (Audit Log).\n\n**Основные принципы:**\n*   **Четкие статусы:** Использование `Enum` для статусов дела (`Intake`, `Under Review`, `Risks Identified`, `Validated`, `Deleted`).\n*   **Soft vs. Hard Delete:** `mark_case_as_deleted` для изменения статуса, `purge_case_data` для безвозвратного удаления.\n*   **GDPR (Purge):** `purge_case_data` должна быть реализована тщательно, удаляя ВСЕ связанные данные из БД и хранилища (и будущих векторных баз).\n*   **RBAC:** Проверка прав пользователя на доступ/изменение дела.\n\n**Ключевые фрагменты кода:**\n\n**`app/db/models.py` (сущности `Case`, `AuditLog`)**\n```python\n# ... (UserRole, Organization, User уже выше) ...\n\nclass CaseStatus(enum.Enum):\n    INTAKE = \"Intake\"\n    UNDER_REVIEW = \"Under Review\"\n    RISKS_IDENTIFIED = \"Risks Identified\"\n    VALIDATED = \"Validated\"\n    DELETED = \"Deleted\" # Для мягкого удаления, перед purge\n\nclass Case(Base):\n    __tablename__ = \"cases\"\n    id = Column(Integer, primary_key=True, index=True)\n    title = Column(String, index=True, nullable=False)\n    description = Column(Text, nullable=True)\n    status = Column(Enum(CaseStatus), default=CaseStatus.INTAKE, nullable=False)\n    owner_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    organization_id = Column(Integer, ForeignKey(\"organizations.id\"), nullable=True)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n    \n    owner = relationship(\"User\", back_populates=\"cases\")\n    organization = relationship(\"Organization\", back_populates=\"cases\")\n    documents = relationship(\"Document\", back_populates=\"case\", cascade=\"all, delete-orphan\") # US-016: Каскадное удаление\n    runs = relationship(\"Run\", back_populates=\"case\", cascade=\"all, delete-orphan\") # US-016: Каскадное удаление\n\nclass AuditLog(Base):\n    __tablename__ = \"audit_logs\"\n    id = Column(Integer, primary_key=True, index=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    case_id = Column(Integer, ForeignKey(\"cases.id\"), nullable=True)\n    document_id = Column(Integer, ForeignKey(\"documents.id\"), nullable=True)\n    run_id = Column(Integer, ForeignKey(\"runs.id\"), nullable=True)\n    action = Column(String, nullable=False) # e.g., \"user_logged_in\", \"case_created\", \"document_uploaded\", \"pve_run_initiated\", \"case_purged\"\n    details = Column(Text, nullable=True) # JSONB field might be better for rich details\n    timestamp = Column(DateTime(timezone=True), server_default=func.now())\n    \n    user = relationship(\"User\", back_populates=\"audit_logs\")\n```\n\n**`app/db/crud.py` (функции для `Case`)**\n```python\nfrom sqlalchemy.orm import Session\nfrom app.db.models import Case, CaseStatus, User, AuditLog, Document\nfrom app.core.schemas import CaseCreate, CaseUpdateStatus\nfrom app.services.storage_service import delete_object # Для purge MinIO/S3\nfrom app.services.audit_service import log_action # Для аудита purge\n\ndef create_case(db: Session, case: CaseCreate, owner_id: int, organization_id: int | None = None) -> Case:\n    db_case = Case(\n        title=case.title,\n        description=case.description,\n        owner_id=owner_id,\n        organization_id=organization_id,\n        status=CaseStatus.INTAKE\n    )\n    db.add(db_case)\n    db.commit()\n    db.refresh(db_case)\n    return db_case\n\ndef get_cases_for_user(db: Session, user: User, skip: int = 0, limit: int = 100) -> list[Case]:\n    # US-002: Список дел на дашборде. Учитываем RBAC (владелец, организация).\n    query = db.query(Case).filter(Case.status != CaseStatus.DELETED)\n\n    if user.role == UserRole.ADMIN:\n        pass # Admin видит все\n    elif user.role == UserRole.ORG_OWNER and user.organization_id:\n        query = query.filter(Case.organization_id == user.organization_id)\n    elif user.role in [UserRole.USER, UserRole.VIEWER]:\n        # Пользователи и просмотрщики видят свои дела и дела организации, если к ним есть доступ\n        # Для MVP User/Viewer видят только свои (или дела своей организации, но без тонкого RBAC)\n        if user.organization_id:\n             query = query.filter((Case.owner_id == user.id) | (Case.organization_id == user.organization_id))\n        else:\n            query = query.filter(Case.owner_id == user.id)\n    else:\n        return [] # Нет прав или некорректная роль\n\n    return query.offset(skip).limit(limit).all()\n\ndef get_case(db: Session, case_id: int) -> Case | None:\n    return db.query(Case).filter(Case.id == case_id, Case.status != CaseStatus.DELETED).first()\n\ndef update_case_status(db: Session, case_id: int, new_status: CaseStatus) -> Case | None:\n    db_case = get_case(db, case_id)\n    if db_case:\n        db_case.status = new_status\n        db.add(db_case)\n        db.commit()\n        db.refresh(db_case)\n    return db_case\n\ndef purge_case_data(db: Session, case: Case, current_user_id: int):\n    # US-016: Полное и безвозвратное удаление всех связанных данных (GDPR).\n    # G-C-010: Верификация полного удаления данных.\n    \n    # 1. Удаление документов и их извлеченных текстов из MinIO/S3\n    documents_to_delete_from_storage = []\n    for doc in case.documents:\n        documents_to_delete_from_storage.append(doc.storage_path)\n        if doc.extracted_text_path:\n            documents_to_delete_from_storage.append(doc.extracted_text_path)\n    \n    for path in documents_to_delete_from_storage:\n        try:\n            delete_object(path)\n        except Exception as e:\n            # Логируем ошибку, но продолжаем, чтобы удалить остальные данные.\n            # Если объект не найден, это тоже ОК.\n            log_action(db, user_id=current_user_id, case_id=case.id, action=\"purge_storage_failed\", details={\"path\": path, \"error\": str(e)})\n\n    # TODO: Если будут embeddings, здесь должна быть логика удаления из векторной БД\n    # vector_db_service.delete_embeddings_for_case(case.id)\n\n    # 2. Удаление AuditLogs, связанных с этим Case.\n    # Это нужно сделать до удаления самого Case, так как AuditLog ссылается на Case.\n    db.query(AuditLog).filter(AuditLog.case_id == case.id).delete(synchronize_session=False)\n\n    # 3. Удаление Case и всех связанных сущностей (documents, runs, findings, evidence)\n    # благодаря cascade=\"all, delete-orphan\" в моделях.\n    db.delete(case)\n    db.commit()\n    log_action(db, user_id=current_user_id, case_id=case.id, action=\"case_purged_complete\") # Логируем после успешного удаления\n\n```\n\n**`app/api/v1/cases.py` (эндпоинты)**\n```python\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.orm import Session\n\nfrom app.db.session import get_db\nfrom app.db.crud import create_case, get_cases_for_user, get_case, update_case_status, purge_case_data\nfrom app.db.models import Case, User, CaseStatus, UserRole\nfrom app.core.schemas import CaseCreate, CasePublic, CaseUpdateStatus, Message\nfrom app.core.security import get_current_user, require_role # get_current_user - для общих доступов, require_role - для админских\nfrom app.services.audit_service import log_action\nfrom app.services.case_service import user_can_access_case, user_can_modify_case # Для RBAC бизнес-логики\n\nrouter = APIRouter()\n\n@router.post(\"/\", response_model=CasePublic, status_code=status.HTTP_201_CREATED)\nasync def create_new_case_endpoint(case_in: CaseCreate, \n                                   current_user: User = Depends(require_role([UserRole.USER, UserRole.ORG_OWNER, UserRole.ADMIN])), \n                                   db: Session = Depends(get_db)):\n    # US-003: Создание нового дела\n    # Если у пользователя есть организация, дело по умолчанию связывается с ней\n    organization_id = current_user.organization_id \n    new_case = create_case(db, case_in, current_user.id, organization_id)\n    log_action(db, user_id=current_user.id, case_id=new_case.id, action=\"case_created\", details={\"title\": new_case.title})\n    return new_case\n\n@router.get(\"/\", response_model=list[CasePublic])\nasync def read_user_cases_endpoint(current_user: User = Depends(get_current_user), db: Session = Depends(get_db)):\n    # US-002: Дашборд со списком дел\n    cases = get_cases_for_user(db, current_user)\n    return cases\n\n@router.get(\"/{case_id}\", response_model=CasePublic)\nasync def read_case_endpoint(case_id: int, \n                             current_user: User = Depends(get_current_user), \n                             db: Session = Depends(get_db)):\n    # US-004: Просмотр деталей дела (Case Workspace)\n    case = get_case(db, case_id)\n    if not case:\n        raise HTTPException(status_code=404, detail=\"Case not found or already deleted.\")\n    \n    if not user_can_access_case(current_user, case): # RBAC для доступа\n        raise HTTPException(status_code=403, detail=\"Not authorized to access this case.\")\n        \n    return case\n\n@router.patch(\"/{case_id}/status\", response_model=CasePublic)\nasync def update_case_current_status_endpoint(case_id: int, \n                                              status_update: CaseUpdateStatus,\n                                              current_user: User = Depends(require_role([UserRole.USER, UserRole.ORG_OWNER, UserRole.ADMIN])), \n                                              db: Session = Depends(get_db)):\n    # Внутренний эндпоинт, который может использоваться PVE или администратором для ручной корректировки.\n    case = get_case(db, case_id)\n    if not case:\n        raise HTTPException(status_code=404, detail=\"Case not found.\")\n\n    if not user_can_modify_case(current_user, case): \n        raise HTTPException(status_code=403, detail=\"Not authorized to modify this case status.\")\n        \n    updated_case = update_case_status(db, case_id, status_update.status)\n    if not updated_case: # Should not happen if get_case found it\n        raise HTTPException(status_code=500, detail=\"Failed to update case status.\")\n    \n    log_action(db, user_id=current_user.id, case_id=case_id, action=\"case_status_updated\", details={\"new_status\": status_update.status.value})\n    return updated_case\n\n@router.delete(\"/{case_id}\", response_model=Message)\nasync def delete_case_and_purge_data_endpoint(case_id: int, \n                                              current_user: User = Depends(require_role([UserRole.USER, UserRole.ORG_OWNER, UserRole.ADMIN])), \n                                              db: Session = Depends(get_db)):\n    # US-016: Удаление дела (Purge) - требуется подтверждение, но в API это просто вызов\n    case = get_case(db, case_id)\n    if not case:\n        raise HTTPException(status_code=404, detail=\"Case not found or already deleted.\")\n    \n    if not user_can_modify_case(current_user, case): \n        raise HTTPException(status_code=403, detail=\"Not authorized to delete this case.\")\n    \n    log_action(db, user_id=current_user.id, case_id=case.id, action=\"case_purge_initiated\", details={\"title\": case.title})\n    \n    # Вызываем функцию purge_case_data для полного удаления\n    purge_case_data(db, case, current_user.id) # Передаем user_id для логирования внутри purge_case_data\n    \n    return {\"message\": f\"Case {case_id} and all associated data have been permanently purged.\"}\n\n```\n**`app/services/case_service.py` (вспомогательные функции для RBAC)**\n```python\nfrom app.db.models import User, Case, UserRole\n\ndef user_can_access_case(user: User, case: Case) -> bool:\n    \"\"\"Проверяет, имеет ли пользователь право доступа к делу.\"\"\"\n    if user.role == UserRole.ADMIN:\n        return True\n    if user.id == case.owner_id:\n        return True\n    if user.organization_id and case.organization_id and user.organization_id == case.organization_id:\n        # Все роли в организации могут просматривать дела, если организация настроена\n        return user.role in [UserRole.ORG_OWNER, UserRole.USER, UserRole.VIEWER]\n    return False\n\ndef user_can_modify_case(user: User, case: Case) -> bool:\n    \"\"\"Проверяет, имеет ли пользователь право изменять/удалять дело.\"\"\"\n    if user.role == UserRole.ADMIN:\n        return True\n    if user.id == case.owner_id and user.role == UserRole.USER:\n        return True\n    if user.organization_id and case.organization_id and user.organization_id == case.organization_id:\n        # Только владелец организации может модифицировать дела в своей организации, кроме тех, что он владеет\n        return user.role == UserRole.ORG_OWNER\n    return False\n```\n\n---\n\n### **4. Логика Пайплайна Загрузки Документов (Document Upload Pipeline Logic)**\n\n**Покрытие US:** US-005 (Загрузка), US-006 (Статус), US-007 (OCR/Extract), US-020 (Валидация файлов), US-015 (Audit Log).\n\n**Основные принципы:**\n*   **Асинхронная обработка:** Использование Celery для выполнения ресурсоемких задач (OCR, извлечение текста) в фоновом режиме.\n*   **Хранение:** Оригинальные документы и извлеченный текст хранятся в MinIO/S3.\n*   **Валидация:** Строгая проверка типов файлов и размеров при загрузке.\n*   **Статусы:** Четкое отслеживание статуса обработки документа.\n\n**Ключевые фрагменты кода:**\n\n**`app/db/models.py` (сущность `Document`)**\n```python\n# ... (Case, User, Organization, AuditLog) ...\n\nclass DocumentStatus(enum.Enum):\n    UPLOADED = \"Uploaded\"\n    VALIDATING = \"Validating\" # US-020\n    SCANNING = \"Scanning\"     # Для антивируса (если будет), или общая фаза обработки\n    OCR_PROCESSING = \"OCR Processing\" # US-007\n    TEXT_EXTRACTED = \"Text Extracted\" # US-007\n    FAILED = \"Failed\"         # Ошибки OCR, валидации и т.д.\n\nclass Document(Base):\n    __tablename__ = \"documents\"\n    id = Column(Integer, primary_key=True, index=True)\n    case_id = Column(Integer, ForeignKey(\"cases.id\"), nullable=False)\n    filename = Column(String, nullable=False) # Имя файла, которое показано пользователю\n    original_filename = Column(String, nullable=False) # Оригинальное имя файла при загрузке\n    file_type = Column(String, nullable=False) # MIME type\n    file_size = Column(Integer, nullable=False) # bytes\n    storage_path = Column(String, unique=True, nullable=False) # Путь в MinIO/S3\n    extracted_text_path = Column(String, nullable=True) # Путь к извлеченному тексту в MinIO/S3\n    status = Column(Enum(DocumentStatus), default=DocumentStatus.UPLOADED, nullable=False) # US-006\n    upload_timestamp = Column(DateTime(timezone=True), server_default=func.now())\n    processed_timestamp = Column(DateTime(timezone=True), nullable=True)\n\n    case = relationship(\"Case\", back_populates=\"documents\")\n```\n\n**`app/services/storage_service.py`**\n```python\nimport io\nfrom minio import Minio\nfrom minio.error import S3Error\nfrom app.core.config import settings\nfrom app.core.exceptions import StorageException\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n# Инициализация клиента MinIO\nminio_client = Minio(\n    settings.MINIO_ENDPOINT,\n    access_key=settings.MINIO_ACCESS_KEY,\n    secret_key=settings.MINIO_SECRET_KEY,\n    secure=False # TODO: Change to True in production with proper certs\n)\n\ndef check_bucket_exists():\n    \"\"\"Проверяет существование бакета и создает его, если не существует.\"\"\"\n    try:\n        if not minio_client.bucket_exists(settings.MINIO_BUCKET_NAME):\n            minio_client.make_bucket(settings.MINIO_BUCKET_NAME)\n            logger.info(f\"MinIO bucket '{settings.MINIO_BUCKET_NAME}' created.\")\n    except S3Error as e:\n        logger.error(f\"Error checking/creating MinIO bucket: {e}\")\n        raise StorageException(f\"Failed to initialize storage: {e}\")\n\ndef upload_object(object_name: str, data: bytes, content_type: str) -> str:\n    \"\"\"Загружает объект в MinIO/S3.\"\"\"\n    try:\n        minio_client.put_object(\n            settings.MINIO_BUCKET_NAME,\n            object_name,\n            io.BytesIO(data),\n            len(data),\n            content_type=content_type\n        )\n        logger.info(f\"Object '{object_name}' uploaded successfully.\")\n        return object_name\n    except S3Error as e:\n        logger.error(f\"Error uploading object '{object_name}': {e}\")\n        raise StorageException(f\"Failed to upload file: {e}\")\n\ndef get_object(object_name: str) -> bytes:\n    \"\"\"Получает объект из MinIO/S3.\"\"\"\n    try:\n        response = minio_client.get_object(settings.MINIO_BUCKET_NAME, object_name)\n        return response.read()\n    except S3Error as e:\n        logger.error(f\"Error getting object '{object_name}': {e}\")\n        raise StorageException(f\"Failed to retrieve file: {e}\")\n    finally:\n        if 'response' in locals():\n            response.close()\n            response.release_conn()\n\ndef delete_object(object_name: str):\n    \"\"\"Удаляет объект из MinIO/S3.\"\"\"\n    try:\n        minio_client.remove_object(settings.MINIO_BUCKET_NAME, object_name)\n        logger.info(f\"Object '{object_name}' deleted successfully.\")\n    except S3Error as e:\n        logger.error(f\"Error deleting object '{object_name}': {e}\")\n        # При удалении (purge) не стоит бросать исключение, если файл уже удален,\n        # это может помешать завершению операции purge. Просто логируем.\n```\n\n**`app/services/ocr_service.py` (US-007, US-020)**\n```python\nimport os\nimport io\nimport mimetypes\nfrom pathlib import Path\nfrom tempfile import NamedTemporaryFile\nimport logging\n\nfrom pypdf import PdfReader\nfrom docx import Document as DocxDocument\nfrom PIL import Image\nimport pytesseract # Requires Tesseract-OCR installed on the system, and 'tesseract-ocr' package\n\nlogger = logging.getLogger(__name__)\n\n# US-005.2, US-020.1: Поддерживаемые MIME типы\nSUPPORTED_MIME_TYPES = {\n    \"application/pdf\": \"pdf\",\n    \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\": \"docx\",\n    \"text/plain\": \"txt\",\n    \"image/jpeg\": \"jpeg\",\n    \"image/png\": \"png\",\n}\n\nMAX_FILE_SIZE_MB = 200 # US-020.2\nMAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024\n\ndef validate_document(file_content: bytes, file_type: str, file_size: int):\n    \"\"\"\n    US-020: Проводит первичную валидацию загружаемых файлов.\n    \"\"\"\n    if file_type not in SUPPORTED_MIME_TYPES:\n        raise ValueError(f\"Unsupported file type: {file_type}. Supported types are: {', '.join(SUPPORTED_MIME_TYPES.keys())}\")\n    \n    if file_size > MAX_FILE_SIZE_BYTES:\n        raise ValueError(f\"File size exceeds limit of {MAX_FILE_SIZE_MB} MB.\")\n    \n    if not file_content:\n        raise ValueError(\"File is empty.\")\n    \n    # TODO (US-020.3): Опционально: интеграция с антивирусным сканером\n\ndef extract_text_from_document(file_content: bytes, file_type: str) -> str:\n    \"\"\"\n    US-007: Извлекает текст из документа в зависимости от его типа.\n    \"\"\"\n    text = \"\"\n    try:\n        if file_type == \"application/pdf\":\n            reader = PdfReader(io.BytesIO(file_content))\n            for page in reader.pages:\n                text += page.extract_text() or \"\"\n        elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n            doc = DocxDocument(io.BytesIO(file_content))\n            for para in doc.paragraphs:\n                text += para.text + \"\\n\"\n        elif file_type == \"text/plain\":\n            text = file_content.decode('utf-8', errors='ignore')\n        elif file_type in [\"image/jpeg\", \"image/png\"]:\n            # Для сканов используем Tesseract OCR\n            with NamedTemporaryFile(delete=False, suffix=f\".{SUPPORTED_MIME_TYPES[file_type]}\") as temp_file:\n                temp_file.write(file_content)\n                temp_file_path = temp_file.name\n            \n            try:\n                img = Image.open(temp_file_path)\n                # lang='eng' можно изменить, если поддерживаются другие языки\n                text = pytesseract.image_to_string(img, lang='eng') \n            finally:\n                os.unlink(temp_file_path) # Удаляем временный файл\n        else:\n            raise ValueError(f\"Unsupported file type for text extraction: {file_type}\")\n    except Exception as e:\n        logger.error(f\"Failed to extract text from document of type {file_type}: {e}\")\n        raise # Перебрасываем для обработки в таске Celery\n\n    return text\n```\n\n**`app/tasks/celery.py`**\n```python\nfrom celery import Celery\nfrom app.core.config import settings\n\ncelery_app = Celery(\n    \"buran_tasks\",\n    broker=settings.CELERY_BROKER_URL,\n    backend=settings.CELERY_RESULT_BACKEND,\n    include=['app.tasks.document_tasks', 'app.tasks.pve_tasks'] # Include other task modules here\n)\n\n# Настройка Celery для надежной обработки задач\ncelery_app.conf.update(\n    task_track_started=True,\n    task_acks_late=True, # Подтверждение после выполнения\n    worker_prefetch_multiplier=1, # Забирать по одной задаче\n    task_soft_time_limit=300, # 5 минут для мягкого завершения\n    task_time_limit=600,      # 10 минут для жесткого завершения\n)\n```\n\n**`app/tasks/document_tasks.py` (Celery задача для OCR/извлечения)**\n```python\nimport logging\nfrom sqlalchemy.orm import Session\nfrom app.tasks.celery import celery_app\nfrom app.db.session import SessionLocal\nfrom app.db.crud import get_document, update_document_status, update_document_extracted_text_path\nfrom app.db.models import DocumentStatus\nfrom app.services import ocr_service, storage_service\nfrom app.services.audit_service import log_action\n\nlogger = logging.getLogger(__name__)\n\n@celery_app.task(name=\"process_document_for_text_extraction\")\ndef process_document_for_text_extraction(document_id: int, user_id: int): # Добавил user_id для AuditLog\n    \"\"\"\n    US-007: Celery задача для выполнения OCR и извлечения текста из документа.\n    \"\"\"\n    db: Session = SessionLocal()\n    document = None\n    try:\n        document = get_document(db, document_id)\n        if not document:\n            logger.error(f\"Document {document_id} not found for processing.\")\n            return\n\n        # US-006: Обновление статуса\n        update_document_status(db, document_id, DocumentStatus.OCR_PROCESSING)\n        log_action(db, user_id=user_id, case_id=document.case_id, document_id=document_id, action=\"document_ocr_started\")\n\n        file_content = storage_service.get_object(document.storage_path) # 1. Загружаем файл\n        extracted_text = ocr_service.extract_text_from_document(file_content, document.file_type) # 2. Извлекаем текст\n\n        # 3. Сохраняем извлеченный текст в хранилище\n        extracted_text_object_name = f\"cases/{document.case_id}/documents/{document_id}/extracted_text.txt\"\n        storage_service.upload_object(extracted_text_object_name, extracted_text.encode('utf-8'), \"text/plain\")\n\n        # 4. Обновляем статус документа в БД\n        update_document_extracted_text_path(db, document_id, extracted_text_object_name)\n        update_document_status(db, document_id, DocumentStatus.TEXT_EXTRACTED)\n        \n        log_action(db, user_id=user_id, case_id=document.case_id, document_id=document_id, action=\"document_text_extracted\")\n        logger.info(f\"Document {document_id} text extraction complete. Status: {DocumentStatus.TEXT_EXTRACTED.value}\")\n\n    except Exception as e:\n        logger.error(f\"Failed to process document {document_id} for text extraction: {e}\")\n        if document:\n            update_document_status(db, document_id, DocumentStatus.FAILED)\n            log_action(db, user_id=user_id, case_id=document.case_id, document_id=document_id, action=\"document_ocr_failed\", details={\"error\": str(e)})\n    finally:\n        db.close()\n```\n\n**`app/api/v1/documents.py` (эндпоинты)**\n```python\nimport os\nimport uuid\nfrom fastapi import APIRouter, Depends, UploadFile, File, HTTPException, status, Response\nfrom sqlalchemy.orm import Session\nimport mimetypes\n\nfrom app.db.session import get_db\nfrom app.db.crud import create_document, get_case, get_document, get_documents_by_case_id\nfrom app.db.models import Document, Case, User, DocumentStatus, UserRole\nfrom app.core.schemas import DocumentPublic, Message\nfrom app.core.security import get_current_user, require_role\nfrom app.services import storage_service, ocr_service\nfrom app.tasks.document_tasks import process_document_for_text_extraction\nfrom app.services.audit_service import log_action\nfrom app.services.case_service import user_can_access_case, user_can_modify_case\n\nrouter = APIRouter()\n\n@router.post(\"/{case_id}/upload\", response_model=DocumentPublic, status_code=status.HTTP_201_CREATED)\nasync def upload_document_endpoint(case_id: int, \n                                   file: UploadFile = File(...),\n                                   current_user: User = Depends(require_role([UserRole.USER, UserRole.ORG_OWNER, UserRole.ADMIN])), \n                                   db: Session = Depends(get_db)):\n    # US-005: Загрузка различных типов документов\n    case = get_case(db, case_id)\n    if not case:\n        raise HTTPException(status_code=404, detail=\"Case not found.\")\n    \n    if not user_can_modify_case(current_user, case): \n        raise HTTPException(status_code=403, detail=\"Not authorized to upload documents to this case.\")\n\n    file_content = await file.read()\n    file.seek(0) # Сбросить указатель после чтения\n    file_size = len(file_content)\n    \n    detected_mime_type = mimetypes.guess_type(file.filename)[0] or file.content_type\n    if not detected_mime_type:\n        raise HTTPException(status_code=400, detail=\"Could not determine file type.\")\n    \n    # US-020: Валидация файлов (MIME-type, размер)\n    try:\n        ocr_service.validate_document(file_content, detected_mime_type, file_size)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n    file_extension = os.path.splitext(file.filename)[1]\n    object_name = f\"cases/{case_id}/{uuid.uuid4()}{file_extension}\"\n\n    try:\n        storage_service.upload_object(object_name, file_content, detected_mime_type)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to upload file to storage: {e}\")\n\n    # Создание записи о документе в БД\n    new_document = create_document(db, case_id=case_id, \n                                   filename=file.filename, \n                                   original_filename=file.filename,\n                                   file_type=detected_mime_type, \n                                   file_size=file_size, \n                                   storage_path=object_name,\n                                   status=DocumentStatus.UPLOADED) # US-006: Начальный статус\n    \n    log_action(db, user_id=current_user.id, case_id=case_id, document_id=new_document.id, action=\"document_uploaded\", details={\"filename\": file.filename, \"file_type\": detected_mime_type})\n\n    # Запуск асинхронной задачи для обработки документа (OCR/извлечение текста)\n    process_document_for_text_extraction.delay(new_document.id, current_user.id) # US-007\n    \n    return new_document\n\n@router.get(\"/{case_id}/documents\", response_model=list[DocumentPublic])\nasync def get_case_documents_endpoint(case_id: int, \n                                      current_user: User = Depends(get_current_user), \n                                      db: Session = Depends(get_db)):\n    # US-004.1: Workspace дела отображает список всех загруженных документов\n    case = get_case(db, case_id)\n    if not case:\n        raise HTTPException(status_code=404, detail=\"Case not found.\")\n    \n    if not user_can_access_case(current_user, case):\n        raise HTTPException(status_code=403, detail=\"Not authorized to access documents for this case.\")\n        \n    documents = get_documents_by_case_id(db, case_id)\n    return documents\n\n@router.get(\"/{case_id}/documents/{document_id}/download\")\nasync def download_document_endpoint(case_id: int, document_id: int,\n                                    current_user: User = Depends(get_current_user), \n                                    db: Session = Depends(get_db)):\n    # Для скачивания оригинального документа\n    document = get_document(db, document_id)\n    if not document or document.case_id != case_id:\n        raise HTTPException(status_code=404, detail=\"Document not found in this case.\")\n\n    case = get_case(db, case_id)\n    if not user_can_access_case(current_user, case):\n        raise HTTPException(status_code=403, detail=\"Not authorized to download documents from this case.\")\n\n    try:\n        file_content = storage_service.get_object(document.storage_path)\n        log_action(db, user_id=current_user.id, case_id=case_id, document_id=document_id, action=\"document_downloaded\", details={\"filename\": document.filename})\n        return Response(content=file_content, media_type=document.file_type, headers={\"Content-Disposition\": f\"attachment;filename={document.original_filename}\"})\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to download document: {e}\")\n\n@router.get(\"/{case_id}/documents/{document_id}/extracted-text\")\nasync def get_extracted_text_endpoint(case_id: int, document_id: int,\n                                    current_user: User = Depends(get_current_user), \n                                    db: Session = Depends(get_db)):\n    # Для отладки или внутреннего UI (например, для просмотра извлеченного текста)\n    document = get_document(db, document_id)\n    if not document or document.case_id != case_id:\n        raise HTTPException(status_code=404, detail=\"Document not found in this case.\")\n\n    case = get_case(db, case_id)\n    if not user_can_access_case(current_user, case):\n        raise HTTPException(status_code=403, detail=\"Not authorized to access this document's extracted text.\")\n\n    if document.status != DocumentStatus.TEXT_EXTRACTED or not document.extracted_text_path:\n        raise HTTPException(status_code=409, detail=\"Text not yet extracted or extraction failed.\")\n\n    try:\n        text_content = storage_service.get_object(document.extracted_text_path)\n        log_action(db, user_id=current_user.id, case_id=case_id, document_id=document_id, action=\"extracted_text_accessed\", details={\"document_id\": document_id})\n        return Response(content=text_content, media_type=\"text/plain\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to retrieve extracted text: {e}\")\n```\n\n---\n\n### **Дополнительные заметки для завершения MVP (Sprints 2-4):**\n\n**Sprint 2: PVE Core Pipeline (Ядро Валидации)**\n*   **US-008 (Структурирование фактов и таймлайна):**\n    *   **`app/services/pve_service.py`**: Здесь будет основная логика. Используем `spaCy` для NER (именованных сущностей) и извлечения дат.\n    *   Например, для `Golden Dataset 2 (Critical Timeline Violation)`:\n        *   Извлекаем все даты из всех документов.\n        *   Сопоставляем даты с ключевыми событиями (увольнение, подача жалобы).\n        *   Реализуем правила, которые проверяют временные интервалы.\n*   **US-009 (Запуск валидации - Run):**\n    *   **`app/api/v1/pve_runs.py`**: Эндпоинт `POST /cases/{case_id}/run`. Он создаст запись `Run` в БД и запустит `celery_app.send_task('run_pve_pipeline', args=[case_id, run_id, user_id])`.\n    *   **`app/db/models.py`**: Добавятся модели `Run`, `Finding`, `Evidence`.\n    *   **`app/tasks/pve_tasks.py`**: Содержит основную Celery задачу `run_pve_pipeline`.\n*   **US-010 (Применение Ruleset) & US-011 (Генерация Finding с Evidence):**\n    *   **`app/services/pve_service.py`**:\n        *   Загрузка правил (например, из JSON-файла, который содержит regex, условия и ожидаемые результаты).\n        *   Итерация по извлеченным фактам и таймлайну, применяя правила.\n        *   **CRITICAL: \"Finding без Evidence запрещён\"**: Каждое правило, которое генерирует `Finding`, ДОЛЖНО быть способно предоставить `doc_id`, `page` (или блок текста), `цитату` и `confidence`. Если `Evidence` не может быть получено, `Finding` не должен быть создан. Это будет явная проверка в `pve_service`.\n    *   Для `Golden Dataset 4 (Incomplete Document Package)`: Правило будет искать упоминание \"письма об увольнении\" и проверять, существует ли документ с таким описанием или типом. `Evidence` будет цитатой, где документ упоминается.\n\n**Sprint 3: Reporting & UX Refinement**\n*   **US-012 (Генерация отчета - PDF/JSON):**\n    *   **`app/services/report_service.py`**:\n        *   Будет использовать `Jinja2` для создания HTML-шаблона отчета.\n        *   `WeasyPrint` или аналогичная библиотека для конвертации HTML в PDF.\n        *   JSON-отчет будет формироваться напрямую из моделей `Finding` и `Evidence`.\n        *   **US-012.5**: Четкий дисклеймер \"THIS IS NOT LEGAL ADVICE. ONLY PROCEDURAL VALIDATION.\" будет внедрен в шаблон отчета.\n        *   **US-012.4**: Метаданные `run_id`, `ruleset_version`, `model_version` будут включены.\n*   **US-013 (Просмотр отчета) & US-014 (Экспорт):**\n    *   Эндпоинты в `app/api/v1/pve_runs.py` для получения PDF и JSON отчетов.\n    *   UI на фронтенде для отображения PDF и кнопок экспорта.\n\n**Sprint 4: Compliance, Security Hardening & QA Readiness**\n*   **US-015 (Audit Log):** `audit_service.py` и модель `AuditLog` уже заложены. Будут добавлены логи для всех Must-have действий.\n*   **US-016 (Purge):** Логика `purge_case_data` уже есть. Будет тщательное тестирование этой функции, как требовал QA.\n*   **US-017 (Версионирование):** `ruleset_version` и `pipeline_version` будут частью модели `Run`.\n*   **Тестирование (DoD, QA Test Plan):**\n    *   **`tests/`**: Полный набор Unit, Integration и E2E тестов.\n    *   **`tests/golden_datasets/`**: Отдельные тестовые сценарии для каждого `Golden Dataset`. Автоматизированные E2E тесты (с использованием Playwright), которые:\n        1.  Загружают документы из `Golden Dataset`.\n        2.  Запускают PVE.\n        3.  Ждут завершения.\n        4.  Скачивают `Report.json` и `Audit Log`.\n        5.  Проверяют `Report.json` на соответствие ожидаемым `Finding`, `Evidence` (включая `doc_id`, `page`, `цитату`, `confidence`).\n        6.  Проверяют `Audit Log` на корректные записи.\n        7.  Проверяют наличие дисклеймера в отчете.\n    *   **Regression Checklist:** Будет выполнен перед каждым релизом.\n    *   **Gate Checklist:** Каждый пункт Блокера будет проверен вручную и/или автоматически перед подтверждением готовности к релизу.\n\n---\n\nЭта детализированная реализация закладывает прочный фундамент для проекта BURAN PVE, обеспечивая функциональность, безопасность, соответствие требованиям и высокую степень аудируемости, что критически важно для юридического продукта."
    }
]